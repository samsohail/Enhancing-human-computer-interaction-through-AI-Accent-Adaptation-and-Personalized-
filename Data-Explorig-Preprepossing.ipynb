{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "R0uKNH4rNnBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3990d6d-9c20-464f-c384-4709ce3b74b2"
      },
      "id": "R0uKNH4rNnBK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea57fbe8-8736-436e-89cb-1ae4e4193baf",
      "metadata": {
        "id": "ea57fbe8-8736-436e-89cb-1ae4e4193baf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFBPUrSgNvOT",
        "outputId": "ff380b7c-134e-4467-eb38-b3223b55f3f7"
      },
      "id": "XFBPUrSgNvOT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/drive/My Drive/en.zip'\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the extraction directory\n",
        "extract_dir = '/content/drive/My Drive/data/extracted_files-2/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "extracted_files = os.listdir(extract_dir)\n",
        "print(extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3eVFhl6Obrc",
        "outputId": "3c466d3d-e0e3-451c-93d7-697d51474c4b"
      },
      "id": "L3eVFhl6Obrc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['en']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab6b936-83b5-42ab-ae2a-09119eebaf15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ab6b936-83b5-42ab-ae2a-09119eebaf15",
        "outputId": "3bfa5d45-1606-4d28-d9eb-9766384d1cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           client_id  \\\n",
            "0  01e8ea298cdecf26e273f5baac3915eb992c493f229686...   \n",
            "1  02cbc1fe01fc67fa72c6e067fbe020399082efbeb57a2b...   \n",
            "2  03b62f72067ec967c423852bef03d1b61e63c156d86f6e...   \n",
            "3  05112cb5965431bbd47abd29b4faea9fb009b5a2e320e0...   \n",
            "4  05d33ad00cc2754da8e542a33a5255f9346535ef1d8619...   \n",
            "\n",
            "                           path  \\\n",
            "0  common_voice_en_39751075.mp3   \n",
            "1  common_voice_en_39589864.mp3   \n",
            "2  common_voice_en_40087973.mp3   \n",
            "3  common_voice_en_39587246.mp3   \n",
            "4  common_voice_en_40117514.mp3   \n",
            "\n",
            "                                         sentence_id  \\\n",
            "0  e5e7d4694b7160add018a08876327f254690c1ab4c39ea...   \n",
            "1  e3e7c913ce32a3b5a58dda5fa1d855f2529ed36e1fa33f...   \n",
            "2  e90c361c9684d01d31bc6e8df3060bc97e536ca707bef4...   \n",
            "3  e3a1d0662e080f880a899b5a5226af16acf61360b1128e...   \n",
            "4  e9475052b6e625f8c5890389e4ffc17a1078dec1483592...   \n",
            "\n",
            "                                            sentence sentence_domain  \\\n",
            "0  Madin was a significant figure of post-war Bir...             NaN   \n",
            "1    Alexandria and Texas were shut down mid-season.             NaN   \n",
            "2                           No runoff was necessary.             NaN   \n",
            "3  He was temporarily in charge of consular affai...             NaN   \n",
            "4                          It was a sickening sight.             NaN   \n",
            "\n",
            "   up_votes  down_votes       age          gender  \\\n",
            "0         2           0       NaN             NaN   \n",
            "1         2           0       NaN             NaN   \n",
            "2         2           0     teens     transgender   \n",
            "3         2           0       NaN             NaN   \n",
            "4         2           0  twenties  male_masculine   \n",
            "\n",
            "                                  accents  variant locale  segment  \n",
            "0  United States English,New York English      NaN     en      NaN  \n",
            "1                                     NaN      NaN     en      NaN  \n",
            "2                        Scottish English      NaN     en      NaN  \n",
            "3                                     NaN      NaN     en      NaN  \n",
            "4                      Australian English      NaN     en      NaN  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the metadata file\n",
        "metadata_path = os.path.join(extract_dir, 'en/validated.tsv')\n",
        "# metadata_path = 'validated.tsv'  # Replace with the correct path to your 'validated.tsv' file\n",
        "metadata = pd.read_csv(metadata_path, sep='\\t')  # Read the TSV file into a DataFrame\n",
        "\n",
        "# Display the first few rows of the DataFrame to understand its structure\n",
        "print(metadata.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e25ddec-3ddc-4b44-ad76-8009bbac5687",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e25ddec-3ddc-4b44-ad76-8009bbac5687",
        "outputId": "d5c3718b-6f18-4bda-ad98-266bd8b903d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique accents in the dataset:\n",
            "['United States English,New York English' 'Scottish English'\n",
            " 'Australian English' 'United States English' 'Northern English'\n",
            " 'United States English,Transgender,California'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'Scottish English,Posh Scottish English'\n",
            " 'United States English,England English,Transatlantic English'\n",
            " 'German English,German native speaker' 'Canadian English'\n",
            " 'Northern Irish,belfast ' 'Icelandic' 'Canadian English,Lisp'\n",
            " 'United States English,midwestern united states' 'Zambia'\n",
            " 'England English'\n",
            " 'Midwestern United States - Chicago,Tinged with southern accent,United States English'\n",
            " 'Slavic English' 'Spanish,american'\n",
            " 'United States English,England English'\n",
            " 'United States English,Hungarian English (English spoken by a Hungarian national)'\n",
            " 'United States English,Philadelphia'\n",
            " 'England English,Surrey accent, Southern English.'\n",
            " 'United States English,Danish'\n",
            " 'England English,Western European non-native English'\n",
            " 'Irish English,England English'\n",
            " 'Latin American accent influenced by American English '\n",
            " 'England English,London English' 'New Zealand English'\n",
            " 'Algeria,Algerian '\n",
            " 'England English,Souther English, long-term resident in Scotland'\n",
            " 'German English,Sick' 'Italian'\n",
            " 'England English,International Southern/London' 'Dutch English'\n",
            " 'United States English,California'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'England English,Singaporean English' 'England English,Luton,Dunstable'\n",
            " 'Slovenian,United States English' 'Chinese-Australian English'\n",
            " 'England English,London/Cockney Accent' 'British,England English'\n",
            " 'England English,Dutch English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'England English,Yorkshire English' 'United States English,Midwestern'\n",
            " 'England English,Sore throat,Masculine ' 'German' 'German English'\n",
            " 'Bengali English,India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'United States English,portuguese' 'american'\n",
            " 'United States English,Minnesotan'\n",
            " 'Scottish English,highland,east highland'\n",
            " 'United States English,Midwestern,Low,Demure' 'Turkish'\n",
            " 'Welsh English,Shropshire' 'United States English,Canadian English'\n",
            " 'England English,India and South Asia (India, Pakistan, Sri Lanka),Essex'\n",
            " 'Chinese English,British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'England English, north yorkshire' 'Blurpy'\n",
            " 'Scottish English,England English' 'Slavic,Russian,Cyrilic'\n",
            " 'North Africa' 'Korean American,Korean American English '\n",
            " 'United States English,A midwestern accent, specific to the St. Louis area.'\n",
            " 'Eastern European English,bulgarian english'\n",
            " 'Canadian English,French Canadian' 'Non Native - French speaker'\n",
            " 'England English,Israeli,Faroe islands,United States English'\n",
            " 'United States English,vietnamese accent'\n",
            " 'Midwestern United States - Chicago,Tinged with southern accent'\n",
            " 'England English,North of England,Lancashire,Mild scouse'\n",
            " 'United States English,Mid Atlantic' 'United States English,Sacramento'\n",
            " 'United States English,Midwestern,Michigan' 'England English,geordie '\n",
            " 'British Indian,England English' 'Swedish'\n",
            " 'Transfemale - US English,United States English,Transgender Woman - US English'\n",
            " 'United States English,Eastern United States'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka),United States English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia),United States English'\n",
            " 'United States English,midwestern Missourian drawl'\n",
            " 'midwestern united states'\n",
            " 'England English,femalepublic school accent, quiet and under articualted finals'\n",
            " 'United States English,Foreign accent' 'United States English,Floridian'\n",
            " 'Germany English,France English'\n",
            " 'United States English,Influenced by living in Maine and Ohio, but I actively tried to drop the Maine accent when I was young.'\n",
            " 'European accent' 'Welsh English' 'England English,United States English'\n",
            " 'England English,Received English, tempered by 45 years living in the USA'\n",
            " 'Transatlantic,Danish English'\n",
            " 'United States English,Pacific North West United States'\n",
            " 'United States English,Australian English,England English,Irish English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English,Indonesian English'\n",
            " 'England English,Slightly lazy Midlands English ,Oxford English'\n",
            " 'United States English,North Indiana'\n",
            " 'United States English,Washington State'\n",
            " 'England English,India and South Asia (India, Pakistan, Sri Lanka),Nepalese'\n",
            " 'United States English,Upstate New York'\n",
            " 'United States English,New Yorker'\n",
            " 'British English / Received Pronunciation (RP)' 'Malaysian English'\n",
            " 'Canadian English,United States English'\n",
            " 'German English,Non native speaker'\n",
            " 'United States English,Midwestern USA']\n"
          ]
        }
      ],
      "source": [
        "# Check if the 'accent' column is present in the dataset\n",
        "if 'accents' in metadata.columns:\n",
        "    # Extract unique accents\n",
        "    unique_accents = metadata['accents'].dropna().unique()  # Drop NaN values and find unique accents\n",
        "    print(\"Unique accents in the dataset:\")\n",
        "    print(unique_accents)  # Display the unique accents\n",
        "else:\n",
        "    print(\"The 'accent' column is not found in the metadata.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e2ccfb-93a0-4219-8228-5d961e26bce3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "23e2ccfb-93a0-4219-8228-5d961e26bce3",
        "outputId": "2876964a-a393-4033-a8f7-5e65671d57b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned and Updated Accents in Metadata:\n",
            "['American English, New York English' 'Scottish English'\n",
            " 'Australian English' 'American English' 'Northern English'\n",
            " 'American English, Transgender, California'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'Scottish English, Posh Scottish English'\n",
            " 'American English, England English, Transatlantic English'\n",
            " 'German English, German native speaker' 'Canadian English'\n",
            " 'Northern Irish, belfast' 'Icelandic' 'Canadian English, Lisp'\n",
            " 'American English, midwestern united states' 'Zambia' 'England English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'American English, England English'\n",
            " 'American English, Hungarian English (English spoken by a Hungarian national)'\n",
            " 'American English, Philadelphia'\n",
            " 'England English, Surrey accent, Southern English.'\n",
            " 'American English, Danish'\n",
            " 'England English, Western European non-native English'\n",
            " 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'England English, London English' 'New Zealand English'\n",
            " 'Algeria, Algerian'\n",
            " 'England English, Souther English, long-term resident in Scotland'\n",
            " 'German English, Sick' 'Italian'\n",
            " 'England English, International Southern/London' 'Dutch English'\n",
            " 'American English, California'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'England English, Singaporean English'\n",
            " 'England English, Luton, Dunstable' 'Slovenian, American English'\n",
            " 'Chinese-Australian English' 'England English, London/Cockney Accent'\n",
            " 'British, England English' 'England English, Dutch English' 'Hungarian'\n",
            " 'Hong Kong English' 'Russian' 'England English, Yorkshire English'\n",
            " 'American English, Midwestern' 'England English, Sore throat, Masculine'\n",
            " 'German' 'German English'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'American English, portuguese' 'american' 'American English, Minnesotan'\n",
            " 'Scottish English, highland, east highland'\n",
            " 'American English, Midwestern, Low, Demure' 'Turkish'\n",
            " 'Welsh English, Shropshire' 'American English, Canadian English'\n",
            " 'England English, India and South Asia (India, Pakistan, Sri Lanka), Essex'\n",
            " 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'England English, north yorkshire' 'Blurpy'\n",
            " 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'American English, A midwestern accent, specific to the St. Louis area.'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Canadian English, French Canadian' 'Non Native - French speaker'\n",
            " 'England English, Israeli, Faroe islands, American English'\n",
            " 'American English, vietnamese accent'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'England English, North of England, Lancashire, Mild scouse'\n",
            " 'American English, Mid Atlantic' 'American English, Sacramento'\n",
            " 'American English, Midwestern, Michigan' 'England English, geordie'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'American English, Eastern United States'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka), American English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'American English, midwestern Missourian drawl'\n",
            " 'midwestern united states'\n",
            " 'England English, femalepublic school accent, quiet and under articualted finals'\n",
            " 'American English, Foreign accent' 'American English, Floridian'\n",
            " 'Germany English, France English'\n",
            " 'American English, Influenced by living in Maine and Ohio, but I actively tried to drop the Maine accent when I was young.'\n",
            " 'European accent' 'Welsh English' 'England English, American English'\n",
            " 'England English, Received English, tempered by 45 years living in the USA'\n",
            " 'Transatlantic, Danish English'\n",
            " 'American English, Pacific North West United States'\n",
            " 'American English, Australian English, England English, Irish English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English, Indonesian English'\n",
            " 'England English, Slightly lazy Midlands English, Oxford English'\n",
            " 'American English, North Indiana' 'American English, Washington State'\n",
            " 'England English, India and South Asia (India, Pakistan, Sri Lanka), Nepalese'\n",
            " 'American English, Upstate New York' 'American English, New Yorker'\n",
            " 'British English / Received Pronunciation (RP)' 'Malaysian English'\n",
            " 'Canadian English, American English' 'German English, Non native speaker'\n",
            " 'American English, Midwestern USA']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-542c03067f7d>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  metadata['accents'] = metadata['accents'].apply(replace_united_states_with_american)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    American English, New York English\n",
              "2                      Scottish English\n",
              "4                    Australian English\n",
              "5                      American English\n",
              "6                      Northern English\n",
              "Name: accents, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>American English, New York English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Scottish English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Australian English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>American English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Northern English</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Step 2: Remove rows with NaN or non-string values from the 'accents' column\n",
        "metadata = metadata[metadata['accents'].apply(lambda x: isinstance(x, str))]  # Keep only rows where 'accents' is a string\n",
        "\n",
        "# Step 3: Define the function to replace accents starting with 'United States' with 'American English'\n",
        "def replace_united_states_with_american(accent):\n",
        "    accents = accent.split(',')  # Split by comma to handle multiple accents\n",
        "    updated_accents = []\n",
        "\n",
        "    for acc in accents:\n",
        "        acc = acc.strip()  # Remove leading and trailing whitespace\n",
        "        if acc.startswith('United States'):\n",
        "            updated_accents.append('American English')  # Replace with 'American English'\n",
        "        else:\n",
        "            updated_accents.append(acc)  # Keep the original accent\n",
        "\n",
        "    return ', '.join(updated_accents)  # Join accents back with commas\n",
        "\n",
        "# Step 4: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(replace_united_states_with_american)\n",
        "\n",
        "# Step 5: Display the updated DataFrame to verify the changes\n",
        "print(\"Cleaned and Updated Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values to check the replacement\n",
        "\n",
        "metadata['accents'].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd50aea9-00e8-4ccc-b7a8-837b50e612fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd50aea9-00e8-4ccc-b7a8-837b50e612fd",
        "outputId": "eb8e7164-a1a5-4d99-d44c-82f7a4b79069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accents Starting with 'American English':\n",
            "['American English, New York English' 'American English'\n",
            " 'American English, Transgender, California'\n",
            " 'American English, England English, Transatlantic English'\n",
            " 'American English, midwestern united states'\n",
            " 'American English, England English'\n",
            " 'American English, Hungarian English (English spoken by a Hungarian national)'\n",
            " 'American English, Philadelphia' 'American English, Danish'\n",
            " 'American English, California' 'American English, Midwestern'\n",
            " 'American English, portuguese' 'American English, Minnesotan'\n",
            " 'American English, Midwestern, Low, Demure'\n",
            " 'American English, Canadian English'\n",
            " 'American English, A midwestern accent, specific to the St. Louis area.'\n",
            " 'American English, vietnamese accent' 'American English, Mid Atlantic'\n",
            " 'American English, Sacramento' 'American English, Midwestern, Michigan'\n",
            " 'American English, Eastern United States'\n",
            " 'American English, midwestern Missourian drawl'\n",
            " 'American English, Foreign accent' 'American English, Floridian'\n",
            " 'American English, Influenced by living in Maine and Ohio, but I actively tried to drop the Maine accent when I was young.'\n",
            " 'American English, Pacific North West United States'\n",
            " 'American English, Australian English, England English, Irish English'\n",
            " 'American English, North Indiana' 'American English, Washington State'\n",
            " 'American English, Upstate New York' 'American English, New Yorker'\n",
            " 'American English, Midwestern USA']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Filter the 'accents' column to select rows starting with 'American English'\n",
        "american_accents = metadata[metadata['accents'].str.startswith('American English', na=False)]  # Filter rows\n",
        "\n",
        "# Step 2: Print the filtered accents\n",
        "print(\"Accents Starting with 'American English':\")\n",
        "print(american_accents['accents'].unique())  # Display unique accents that start with 'American English'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3853ca-a9df-465f-b376-694d5720f910",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3853ca-a9df-465f-b376-694d5720f910",
        "outputId": "4d51af06-d10b-42e4-a501-03d68348d364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of 'American English': 479\n"
          ]
        }
      ],
      "source": [
        "# Example: To check the count of 'American English'\n",
        "accent_to_check = 'American English'  # Replace with the accent you want to check\n",
        "\n",
        "# Count the occurrences of 'American English' in the 'accents' column\n",
        "accent_count = metadata['accents'].value_counts().get(accent_to_check, 0)\n",
        "\n",
        "# Print the count of the specified accent\n",
        "print(f\"Count of '{accent_to_check}': {accent_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc098fbc-123b-4586-b312-2d8a0235f76e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc098fbc-123b-4586-b312-2d8a0235f76e",
        "outputId": "04999fc7-a9a7-4295-ced0-d7e24751071d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'Scottish English' 'Australian English'\n",
            " 'Northern English' 'India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'Scottish English, Posh Scottish English'\n",
            " 'German English, German native speaker' 'Canadian English'\n",
            " 'Northern Irish, belfast' 'Icelandic' 'Canadian English, Lisp' 'Zambia'\n",
            " 'England English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american'\n",
            " 'England English, Surrey accent, Southern English.'\n",
            " 'England English, Western European non-native English'\n",
            " 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'England English, London English' 'New Zealand English'\n",
            " 'Algeria, Algerian'\n",
            " 'England English, Souther English, long-term resident in Scotland'\n",
            " 'German English, Sick' 'Italian'\n",
            " 'England English, International Southern/London' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'England English, Singaporean English'\n",
            " 'England English, Luton, Dunstable' 'Slovenian, American English'\n",
            " 'Chinese-Australian English' 'England English, London/Cockney Accent'\n",
            " 'British, England English' 'England English, Dutch English' 'Hungarian'\n",
            " 'Hong Kong English' 'Russian' 'England English, Yorkshire English'\n",
            " 'England English, Sore throat, Masculine' 'German' 'German English'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Scottish English, highland, east highland' 'Turkish'\n",
            " 'Welsh English, Shropshire'\n",
            " 'England English, India and South Asia (India, Pakistan, Sri Lanka), Essex'\n",
            " 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'England English, north yorkshire' 'Blurpy'\n",
            " 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Canadian English, French Canadian' 'Non Native - French speaker'\n",
            " 'England English, Israeli, Faroe islands, American English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'England English, North of England, Lancashire, Mild scouse'\n",
            " 'England English, geordie' 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka), American English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states'\n",
            " 'England English, femalepublic school accent, quiet and under articualted finals'\n",
            " 'Germany English, France English' 'European accent' 'Welsh English'\n",
            " 'England English, American English'\n",
            " 'England English, Received English, tempered by 45 years living in the USA'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English'\n",
            " 'England English, Slightly lazy Midlands English, Oxford English'\n",
            " 'England English, India and South Asia (India, Pakistan, Sri Lanka), Nepalese'\n",
            " 'British English / Received Pronunciation (RP)' 'Malaysian English'\n",
            " 'Canadian English, American English' 'German English, Non native speaker']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents starting with 'American English'\n",
        "def generalize_american_english(accent):\n",
        "    if accent.startswith('American English'):\n",
        "        return 'American English'  # Generalize to 'American English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_american_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc7e7b6-3b35-4b6f-bcc6-90d66f9e8bef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bc7e7b6-3b35-4b6f-bcc6-90d66f9e8bef",
        "outputId": "605ca6b5-d807-45ba-93d1-0bb35fffbe91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'Scottish English' 'Australian English'\n",
            " 'Northern English' 'India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'Scottish English, Posh Scottish English'\n",
            " 'German English, German native speaker' 'Canadian English'\n",
            " 'Northern Irish, belfast' 'Icelandic' 'Canadian English, Lisp' 'Zambia'\n",
            " 'British English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'German English, Sick'\n",
            " 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'German' 'German English'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Scottish English, highland, east highland' 'Turkish'\n",
            " 'Welsh English, Shropshire' 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Canadian English, French Canadian' 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka), American English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'Germany English, France English'\n",
            " 'European accent' 'Welsh English' 'Transatlantic, Danish English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English, Indonesian English'\n",
            " 'British English / Received Pronunciation (RP)' 'Malaysian English'\n",
            " 'Canadian English, American English' 'German English, Non native speaker']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the function to generalize accents starting with 'American English'\n",
        "def generalize_american_english(accent):\n",
        "    if accent.startswith('England English'):\n",
        "        return 'British English'  # Generalize to 'American English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_american_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3d6ab0-d4b9-4bb9-8e5c-5b4eeb022b72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d3d6ab0-d4b9-4bb9-8e5c-5b4eeb022b72",
        "outputId": "7e8cdfe5-3334-4c07-aaa1-a226c4abcc10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'Scottish English' 'Australian English'\n",
            " 'Northern English' 'India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'Scottish English, Posh Scottish English'\n",
            " 'German English, German native speaker' 'Canadian English'\n",
            " 'Northern Irish, belfast' 'Icelandic' 'Canadian English, Lisp' 'Zambia'\n",
            " 'British English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'German English, Sick'\n",
            " 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'German' 'German English'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Scottish English, highland, east highland' 'Turkish'\n",
            " 'Welsh English, Shropshire' 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Canadian English, French Canadian' 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka), American English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'Germany English, France English'\n",
            " 'European accent' 'Welsh English' 'Transatlantic, Danish English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English, Indonesian English'\n",
            " 'Malaysian English' 'Canadian English, American English'\n",
            " 'German English, Non native speaker']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the function to generalize accents starting with 'American English'\n",
        "def generalize_american_english(accent):\n",
        "    if accent.startswith('British English'):\n",
        "        return 'British English'  # Generalize to 'American English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_american_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a16fa0f-5aff-432d-b040-b1cd1e29daa1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a16fa0f-5aff-432d-b040-b1cd1e29daa1",
        "outputId": "e893d1d9-ca49-45f2-c720-d8b628c62095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'Scottish English' 'Australian English'\n",
            " 'Northern English' 'India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'Scottish English, Posh Scottish English'\n",
            " 'German English, German native speaker' 'Canadian English'\n",
            " 'Northern Irish, belfast' 'Icelandic' 'Zambia' 'British English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'German English, Sick'\n",
            " 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'German' 'German English'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Scottish English, highland, east highland' 'Turkish'\n",
            " 'Welsh English, Shropshire' 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka), American English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'Germany English, France English'\n",
            " 'European accent' 'Welsh English' 'Transatlantic, Danish English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English, Indonesian English'\n",
            " 'Malaysian English' 'German English, Non native speaker']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Define the function to generalize accents starting with 'American English'\n",
        "def generalize_american_english(accent):\n",
        "    if accent.startswith('Canadian English'):\n",
        "        return 'Canadian English'  # Generalize to 'American English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_american_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5faae728-5c01-4e14-bff4-04a2d8eecb9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5faae728-5c01-4e14-bff4-04a2d8eecb9b",
        "outputId": "1bcea0df-6e43-4043-dc33-148012347e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'Scottish English' 'Australian English'\n",
            " 'Northern English' 'India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'Scottish English, Posh Scottish English'\n",
            " 'German English, German native speaker' 'Canadian English'\n",
            " 'Northern Irish, belfast' 'Icelandic' 'Zambia' 'British English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'German English, Sick'\n",
            " 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'German' 'German English'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Scottish English, highland, east highland' 'Turkish'\n",
            " 'Welsh English, Shropshire' 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'India and South Asia (India, Pakistan, Sri Lanka), American English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'Germany English, France English'\n",
            " 'European accent' 'Welsh English' 'Transatlantic, Danish English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English, Indonesian English'\n",
            " 'Malaysian English' 'German English, Non native speaker']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the function to generalize accents starting with 'American English'\n",
        "def generalize_american_english(accent):\n",
        "    if accent.startswith('Northern English'):\n",
        "        return 'Northern English'  # Generalize to 'American English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_american_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d6b98b7-48c2-4766-8e89-05f8dc49c062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d6b98b7-48c2-4766-8e89-05f8dc49c062",
        "outputId": "89af160d-16db-420c-f887-258a5a5e3967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'Scottish English' 'Australian English'\n",
            " 'Northern English' 'South Asian English'\n",
            " 'Scottish English, Posh Scottish English'\n",
            " 'German English, German native speaker' 'Canadian English'\n",
            " 'Northern Irish, belfast' 'Icelandic' 'Zambia' 'British English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'German English, Sick'\n",
            " 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'German' 'German English'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Scottish English, highland, east highland' 'Turkish'\n",
            " 'Welsh English, Shropshire' 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'Germany English, France English'\n",
            " 'European accent' 'Welsh English' 'Transatlantic, Danish English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English, Indonesian English'\n",
            " 'Malaysian English' 'German English, Non native speaker']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the function to generalize accents starting with 'American English'\n",
        "def generalize_american_english(accent):\n",
        "    if accent.startswith('India and South Asia'):\n",
        "        return 'South Asian English'  # Generalize to 'American English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_american_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419c985b-2709-49d9-a58a-d4cb38113bf4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "419c985b-2709-49d9-a58a-d4cb38113bf4",
        "outputId": "cdc1b41c-b958-4534-cc2a-525c6a5a5314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'Scottish English' 'Australian English'\n",
            " 'Northern English' 'South Asian English'\n",
            " 'Scottish English, Posh Scottish English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'British English'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Scottish English, highland, east highland' 'Turkish'\n",
            " 'Welsh English, Shropshire' 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Scottish English, England English' 'Slavic, Russian, Cyrilic'\n",
            " 'North Africa' 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the function to generalize accents starting with 'American English'\n",
        "def generalize_american_english(accent):\n",
        "    if accent.startswith('German'):\n",
        "        return 'European English'  # Generalize to 'American English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_american_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ec8b3f-9a2f-433b-b13a-84088411b053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ec8b3f-9a2f-433b-b13a-84088411b053",
        "outputId": "12d40b9b-2e57-41b0-c8d5-a4dd21018541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'Northern English' 'South Asian English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'Bengali English, India and South Asia (India, Pakistan, Sri Lanka)'\n",
            " 'american' 'Turkish' 'Welsh English, Shropshire'\n",
            " 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Slavic, Russian, Cyrilic' 'North Africa'\n",
            " 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'British Indian, England English' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Define the function to generalize accents containing 'German'\n",
        "def generalize_to_european_english(accent):\n",
        "    if 'Scottish' in accent:  # Check if 'German' is anywhere in the accent string\n",
        "        return 'British English'  # Generalize to 'European English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_european_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b4f1f2-736f-4f99-ab3f-16afeb644f36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09b4f1f2-736f-4f99-ab3f-16afeb644f36",
        "outputId": "8b808b21-dd48-4696-c647-60b8a3300a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'Northern English' 'South Asian English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent, American English'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'South Asia English' 'american' 'Turkish' 'Welsh English, Shropshire'\n",
            " 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Slavic, Russian, Cyrilic' 'North Africa'\n",
            " 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker'\n",
            " 'Midwestern United States - Chicago, Tinged with southern accent'\n",
            " 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Define the function to generalize accents containing 'German'\n",
        "def generalize_to_european_english(accent):\n",
        "    if 'India' in accent:  # Check if 'German' is anywhere in the accent string\n",
        "        return 'South Asia English'  # Generalize to 'European English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_european_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faeb656b-a7f4-48cb-ac96-e68f07e9a54f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faeb656b-a7f4-48cb-ac96-e68f07e9a54f",
        "outputId": "c5020119-b3a8-4a4f-9cf7-041a0a0abaa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'Northern English' 'South Asian English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'Chinese-Australian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'South Asia English' 'american' 'Turkish' 'Welsh English, Shropshire'\n",
            " 'Chinese English, British English'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Slavic, Russian, Cyrilic' 'North Africa'\n",
            " 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'German'\n",
        "def generalize_to_european_english(accent):\n",
        "    if 'United States' in accent:  # Check if 'German' is anywhere in the accent string\n",
        "        return 'American English'  # Generalize to 'European English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_european_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3851ece3-53e5-4c88-95e8-683a4e3b0b14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3851ece3-53e5-4c88-95e8-683a4e3b0b14",
        "outputId": "ca25a323-6293-4859-fb00-1dcfa2da4087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'Northern English' 'South Asian English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'Dutch English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia)' 'Irish English'\n",
            " 'Slovenian, American English' 'East Asian English'\n",
            " 'British, England English' 'Hungarian' 'Hong Kong English' 'Russian'\n",
            " 'South Asia English' 'american' 'Turkish' 'Welsh English, Shropshire'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Slavic, Russian, Cyrilic' 'North Africa'\n",
            " 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'Southern African (South Africa, Zimbabwe, Namibia), American English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'German'\n",
        "def generalize_to_european_english(accent):\n",
        "    if 'Chinese' in accent:  # Check if 'German' is anywhere in the accent string\n",
        "        return 'East Asian English'  # Generalize to 'European English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_european_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8582254b-8603-4808-9a53-7ed85c6c953a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8582254b-8603-4808-9a53-7ed85c6c953a",
        "outputId": "f742e19e-716f-42f9-d4e6-f0b582eb1f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'Northern English' 'South Asian English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'Dutch English'\n",
            " 'African English' 'Irish English' 'Slovenian, American English'\n",
            " 'East Asian English' 'British, England English' 'Hungarian'\n",
            " 'Hong Kong English' 'Russian' 'South Asia English' 'american' 'Turkish'\n",
            " 'Welsh English, Shropshire'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Taiwanese English'\n",
            " 'Blurpy' 'Slavic, Russian, Cyrilic' 'North Africa'\n",
            " 'Korean American, Korean American English'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'German'\n",
        "def generalize_to_european_english(accent):\n",
        "    if 'African' in accent:  # Check if 'German' is anywhere in the accent string\n",
        "        return 'African English'  # Generalize to 'European English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_european_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3012733a-4eb1-48dd-948e-f0f0237c28e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3012733a-4eb1-48dd-948e-f0f0237c28e2",
        "outputId": "c7d75923-d276-454c-f931-be657ce895b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'Northern English' 'South Asian English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'Slavic English' 'Spanish, american' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'Dutch English'\n",
            " 'African English' 'Irish English' 'Slovenian, American English'\n",
            " 'East Asian English' 'British, England English' 'Hungarian' 'Russian'\n",
            " 'South Asia English' 'american' 'Turkish' 'Welsh English, Shropshire'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Blurpy'\n",
            " 'Slavic, Russian, Cyrilic' 'North Africa'\n",
            " 'Eastern European English, bulgarian english'\n",
            " 'Non Native - French speaker' 'Swedish'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Transatlantic, Danish English' 'Singaporean English' 'Filipino'\n",
            " 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'Hong Kong' in accent or 'Taiwanese' in accent or 'Korean' in accent:\n",
        "        return 'East Asian English'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2368cba4-1f9f-43d0-b6a1-d3d447d07236",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2368cba4-1f9f-43d0-b6a1-d3d447d07236",
        "outputId": "7582d387-c479-43e9-cac9-69ecede6bc16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'Northern English' 'South Asian English' 'European English'\n",
            " 'Canadian English' 'Northern Irish, belfast' 'Icelandic' 'Zambia'\n",
            " 'Slavic English' 'Irish English, England English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'African English'\n",
            " 'Irish English' 'Slovenian, American English' 'East Asian English'\n",
            " 'British, England English' 'South Asia English' 'american' 'Turkish'\n",
            " 'Welsh English, Shropshire'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Blurpy'\n",
            " 'North Africa' 'Eastern European English, bulgarian english'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'midwestern united states' 'European accent' 'Welsh English'\n",
            " 'Singaporean English' 'Filipino' 'Malaysian English, Indonesian English'\n",
            " 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'Dutch' in accent or 'Hungarian' in accent or 'Russian' in accent or 'Bulgarian' in accent or 'Danish' in accent or 'Swedish' in accent or 'Spanish' in accent or 'French' in accent:\n",
        "        return 'European English'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4dfff1-fd1e-4119-a92a-c1fccce459cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb4dfff1-fd1e-4119-a92a-c1fccce459cf",
        "outputId": "1430b2c5-4a0e-489a-a9e8-9683c736cc17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'South Asian English' 'European English' 'Canadian English' 'Icelandic'\n",
            " 'Zambia' 'Slavic English'\n",
            " 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'Italian' 'African English'\n",
            " 'Slovenian, American English' 'East Asian English' 'South Asia English'\n",
            " 'american' 'Turkish' 'Немного русский акцент произношения, съедание слов'\n",
            " 'Blurpy' 'North Africa' 'Eastern European English, bulgarian english'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'midwestern united states' 'European accent' 'Singaporean English'\n",
            " 'Filipino' 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'Northern English' in accent or 'Irish' in accent or 'England' in accent or 'Welsh' in accent:\n",
        "        return 'British English'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49afec24-0507-4e6e-b983-17ff2812c323",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49afec24-0507-4e6e-b983-17ff2812c323",
        "outputId": "5aa8fb68-12ce-4faa-8ff4-380ef42d3fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'South Asian English' 'European English' 'Canadian English' 'Icelandic'\n",
            " 'Zambia' 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'African English'\n",
            " 'Slovenian, American English' 'East Asian English' 'South Asia English'\n",
            " 'american' 'Turkish' 'Немного русский акцент произношения, съедание слов'\n",
            " 'Blurpy' 'North Africa'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'midwestern united states' 'European accent' 'Singaporean English'\n",
            " 'Filipino' 'Malaysian English, Indonesian English' 'Malaysian English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'Slavic' in accent or 'Italian' in accent or 'Eastern European English' in accent or 'Welsh' in accent:\n",
        "        return 'European English'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "575e7fb8-c958-4948-8011-05aff1566ce0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "575e7fb8-c958-4948-8011-05aff1566ce0",
        "outputId": "10c8274e-f41e-4c94-ea23-7898e60e9669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'South Asian English' 'European English' 'Canadian English' 'Icelandic'\n",
            " 'Zambia' 'Latin American accent influenced by American English'\n",
            " 'New Zealand English' 'Algeria, Algerian' 'African English'\n",
            " 'Slovenian, American English' 'East Asian English' 'South Asia English'\n",
            " 'american' 'Turkish' 'Немного русский акцент произношения, съедание слов'\n",
            " 'Blurpy' 'North Africa'\n",
            " 'Transfemale - US English, American English, Transgender Woman - US English'\n",
            " 'midwestern united states' 'European accent']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'Singaporean' in accent or 'Filipino' in accent or 'Malaysian' in accent or 'Indonesian' in accent:\n",
        "        return 'East Asian English'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "832ecc0e-392f-4d93-9a85-1fc3a8a802b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832ecc0e-392f-4d93-9a85-1fc3a8a802b2",
        "outputId": "2619d4e1-dfef-4187-fb15-e1378535f201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'South Asian English' 'European English' 'Canadian English' 'Icelandic'\n",
            " 'Zambia' 'New Zealand English' 'Algeria, Algerian' 'African English'\n",
            " 'East Asian English' 'South Asia English' 'american' 'Turkish'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Blurpy'\n",
            " 'North Africa' 'European accent']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'Latin American accent influenced by American English' in accent or 'Slovenian' in accent or 'US English' in accent or 'midwestern united states' in accent:\n",
        "        return 'American English'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c78d46f-7b47-4df1-91cc-98e8d0149c39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c78d46f-7b47-4df1-91cc-98e8d0149c39",
        "outputId": "732d6eee-3666-4154-e0ad-7f1c98e42805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English' 'British English' 'Australian English'\n",
            " 'South Asian English' 'European English' 'Canadian English' 'Icelandic'\n",
            " 'African English' 'New Zealand English' 'East Asian English'\n",
            " 'South Asia English' 'american' 'Turkish'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Blurpy'\n",
            " 'European accent']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'Zambia' in accent or 'Slovenian' in accent or 'Algeria' in accent or 'North Africa' in accent:\n",
        "        return 'African English'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee51f1f3-1a41-407b-9d78-e67426a194e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee51f1f3-1a41-407b-9d78-e67426a194e3",
        "outputId": "f8508c30-ccf7-4d1c-99ff-491b9189b341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English Accent' 'British English' 'Australian English'\n",
            " 'South Asian English' 'European English' 'Canadian English' 'Icelandic'\n",
            " 'African English' 'New Zealand English' 'East Asian English'\n",
            " 'South Asia English' 'Turkish'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Blurpy'\n",
            " 'European accent']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'American English' in accent or 'american' in accent:\n",
        "        return 'American English Accent'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d7cc50-9179-454a-a62c-9084efc319b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69d7cc50-9179-454a-a62c-9084efc319b8",
        "outputId": "b4d7a5e0-b795-4349-913c-6b20f4e80032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English Accent' 'British English' 'Australian English'\n",
            " 'Asian English Accent' 'European English' 'Canadian English' 'Icelandic'\n",
            " 'African English' 'New Zealand English' 'South Asia English' 'Turkish'\n",
            " 'Немного русский акцент произношения, съедание слов' 'Blurpy'\n",
            " 'European accent']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'South Asian English' in accent or 'East Asian English' in accent:\n",
        "        return 'Asian English Accent'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e66d504-d657-40f0-a7ce-2768c22c9305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e66d504-d657-40f0-a7ce-2768c22c9305",
        "outputId": "2b2d2e32-09b9-42a9-9f55-12155370430a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English Accent' 'British English' 'Australian English'\n",
            " 'Asian English Accent' 'European English Accent' 'Canadian English'\n",
            " 'Icelandic' 'African English' 'New Zealand English' 'South Asia English'\n",
            " 'Turkish' 'Немного русский акцент произношения, съедание слов' 'Blurpy']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'European accent' in accent or 'European English' in accent:\n",
        "        return 'European English Accent'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11126421-cb37-45d0-ba04-1b58b99231a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11126421-cb37-45d0-ba04-1b58b99231a1",
        "outputId": "ab2c1dd7-34d9-4c30-9ba1-6aaa4979319a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency of unclear accents:\n",
            "American English Accent: 719\n",
            "Icelandic: 1\n",
            "Turkish: 1\n",
            "Немного русский акцент произношения, съедание слов: 1\n",
            "Blurpy: 1\n"
          ]
        }
      ],
      "source": [
        "# Check the frequency of each accent in the DataFrame\n",
        "accent_counts = metadata['accents'].value_counts()\n",
        "\n",
        "# Display the counts for the unclear accents\n",
        "print(\"Frequency of unclear accents:\")\n",
        "for accent in ['American English Accent','Icelandic', 'Turkish', 'Немного русский акцент произношения, съедание слов', 'Blurpy']:\n",
        "    print(f\"{accent}: {accent_counts.get(accent, 0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef235a1e-ab10-460d-bc59-75e16cce4fe8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef235a1e-ab10-460d-bc59-75e16cce4fe8",
        "outputId": "f8992304-ec2c-4297-fa53-61e5cf5bdb26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accents after removing unclear categories:\n",
            "['American English Accent' 'British English' 'Australian English'\n",
            " 'Asian English Accent' 'European English Accent' 'Canadian English'\n",
            " 'African English' 'New Zealand English' 'South Asia English']\n"
          ]
        }
      ],
      "source": [
        "# List of unclear accents to remove\n",
        "unclear_accents = ['Icelandic', 'Turkish', 'Немного русский акцент произношения, съедание слов', 'Blurpy']\n",
        "\n",
        "# Filter the DataFrame to exclude these accents\n",
        "metadata = metadata[~metadata['accents'].isin(unclear_accents)]\n",
        "\n",
        "# Display the unique accents to verify the changes\n",
        "print(\"Accents after removing unclear categories:\")\n",
        "print(metadata['accents'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7e1923-0285-443e-96e4-a416eb6b3aad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7e1923-0285-443e-96e4-a416eb6b3aad",
        "outputId": "722661b0-4780-4b10-8746-e26023560b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generalized Accents in Metadata:\n",
            "['American English Accent' 'British English' 'Australian English'\n",
            " 'Asian English Accent' 'European English Accent' 'Canadian English'\n",
            " 'African English' 'New Zealand English']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the function to generalize accents containing 'African' or 'South African'\n",
        "def generalize_to_african_english(accent):\n",
        "    # Check if 'African' or 'South African' is anywhere in the accent string\n",
        "    if 'South Asia English' in accent:\n",
        "        return 'Asian English Accent'  # Generalize to 'African English'\n",
        "    return accent  # Keep other accents unchanged\n",
        "\n",
        "# Step 2: Apply the function to the 'accents' column in your DataFrame\n",
        "metadata['accents'] = metadata['accents'].apply(generalize_to_african_english)\n",
        "\n",
        "# Step 3: Print the unique accents to verify the changes\n",
        "print(\"Generalized Accents in Metadata:\")\n",
        "print(metadata['accents'].unique())  # Display unique values after generalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b29e877-2b84-4cef-9526-d822b4f5a64a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b29e877-2b84-4cef-9526-d822b4f5a64a",
        "outputId": "436b32d5-2808-48be-b0f4-b0ff12cddd3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency of unclear accents:\n",
            "American English Accent: 719\n",
            "British English: 394\n",
            "Australian English: 139\n",
            "Asian English Accent: 143\n",
            "European English Accent: 105\n",
            "Canadian English: 198\n",
            "African English: 14\n",
            "New Zealand English: 17\n"
          ]
        }
      ],
      "source": [
        "# Check the frequency of each accent in the DataFrame\n",
        "accent_counts = metadata['accents'].value_counts()\n",
        "\n",
        "# Display the counts for the unclear accents\n",
        "print(\"Frequency of unclear accents:\")\n",
        "for accent in ['American English Accent','British English', 'Australian English', 'Asian English Accent', 'European English Accent','Canadian English','African English','New Zealand English']:\n",
        "    print(f\"{accent}: {accent_counts.get(accent, 0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391ed43e-ddc1-4a2d-8f94-38ed7704dfea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "391ed43e-ddc1-4a2d-8f94-38ed7704dfea",
        "outputId": "39bfed43-d574-4da8-e481-3725b8f2e5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broader Categories for Accent Normalization:\n",
            "broader_accents\n",
            "North American English    917\n",
            "British English           550\n",
            "Asian English             143\n",
            "European English          105\n",
            "African English            14\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Define a function to merge accents into broader categories\n",
        "def merge_into_broad_categories(accent):\n",
        "    # Merging into broader categories\n",
        "    if accent in ['American English Accent', 'Canadian English']:\n",
        "        return 'North American English'\n",
        "    elif accent in ['British English', 'Australian English', 'New Zealand English']:\n",
        "        return 'British English'\n",
        "    elif accent == 'Asian English Accent':\n",
        "        return 'Asian English'\n",
        "    elif accent == 'European English Accent':\n",
        "        return 'European English'\n",
        "    elif accent == 'African English':\n",
        "        return 'African English'\n",
        "    else:\n",
        "        return accent  # Keep the original if it doesn't match any of the above\n",
        "\n",
        "# Step 2: Apply the function to merge categories in the 'accents' column of the DataFrame\n",
        "metadata['broader_accents'] = metadata['accents'].apply(merge_into_broad_categories)\n",
        "\n",
        "# Step 3: Print the resulting unique accents to verify the changes\n",
        "print(\"Broader Categories for Accent Normalization:\")\n",
        "print(metadata['broader_accents'].value_counts())  # Display the count of each broader accent category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e9a04d-86d4-49aa-a50e-5a3dbf8b373a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "c6e9a04d-86d4-49aa-a50e-5a3dbf8b373a",
        "outputId": "7a284fcd-71c4-4310-c8ed-3630c938d248"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    North American English\n",
              "2           British English\n",
              "4           British English\n",
              "5    North American English\n",
              "6           British English\n",
              "Name: broader_accents, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>broader_accents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>North American English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>British English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>British English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>North American English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>British English</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "metadata['broader_accents'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca93132-2707-4f40-b676-70fb9c465fdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eca93132-2707-4f40-b676-70fb9c465fdf",
        "outputId": "f4c06c74-6498-47a0-d144-1fc79270bee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique accents in the dataset:\n",
            "['North American English' 'British English' 'Asian English'\n",
            " 'European English' 'African English']\n"
          ]
        }
      ],
      "source": [
        "# Check if the 'accent' column is present in the dataset\n",
        "if 'broader_accents' in metadata.columns:\n",
        "    # Extract unique accents\n",
        "    unique_accents = metadata['broader_accents'].dropna().unique()  # Drop NaN values and find unique accents\n",
        "    print(\"Unique accents in the dataset:\")\n",
        "    print(unique_accents)  # Display the unique accents\n",
        "else:\n",
        "    print(\"The 'accent' column is not found in the metadata.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af781733-1984-4cba-9487-a70014ece919",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af781733-1984-4cba-9487-a70014ece919",
        "outputId": "91057752-ff30-4a52-cdbd-3de3dbdaa20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broader Categories for Accent Normalization:\n",
            "broader_accents\n",
            "North American English    917\n",
            "British English           550\n",
            "Asian English             143\n",
            "European English          105\n",
            "African English            14\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Print the resulting unique accents to verify the changes\n",
        "print(\"Broader Categories for Accent Normalization:\")\n",
        "print(metadata['broader_accents'].value_counts())  # Display the count of each broader accent category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e40e3e-8024-4f9f-bbbe-d1d9c3309135",
      "metadata": {
        "id": "87e40e3e-8024-4f9f-bbbe-d1d9c3309135"
      },
      "outputs": [],
      "source": [
        "# Step 2: Specify the broader accent categories you want to work with\n",
        "target_accents = ['North American English', 'British English', 'Asian English', 'European English', 'African English']\n",
        "\n",
        "# Step 3: Filter the DataFrame based on the target accents\n",
        "filtered_df = metadata[metadata['broader_accents'].isin(target_accents)]  # 'broader_accents' is the column with the accent labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the first few rows to understand the structure\n",
        "print(filtered_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR6agJgNVPBQ",
        "outputId": "9169f957-d477-41d6-c8f3-7c102e34bbbd"
      },
      "id": "MR6agJgNVPBQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           client_id  \\\n",
            "0  01e8ea298cdecf26e273f5baac3915eb992c493f229686...   \n",
            "2  03b62f72067ec967c423852bef03d1b61e63c156d86f6e...   \n",
            "4  05d33ad00cc2754da8e542a33a5255f9346535ef1d8619...   \n",
            "5  08072f2de4dcc2bfec5058dca41eb9535b61ccd193ecc4...   \n",
            "6  083af8bc921baf15ad5d8c8c876f4ecaf4f52bf6370161...   \n",
            "\n",
            "                           path  \\\n",
            "0  common_voice_en_39751075.mp3   \n",
            "2  common_voice_en_40087973.mp3   \n",
            "4  common_voice_en_40117514.mp3   \n",
            "5  common_voice_en_39603786.mp3   \n",
            "6  common_voice_en_39603175.mp3   \n",
            "\n",
            "                                         sentence_id  \\\n",
            "0  e5e7d4694b7160add018a08876327f254690c1ab4c39ea...   \n",
            "2  e90c361c9684d01d31bc6e8df3060bc97e536ca707bef4...   \n",
            "4  e9475052b6e625f8c5890389e4ffc17a1078dec1483592...   \n",
            "5  e4657d8d47be955eb14e04cd1c2a2b9ef89d310f639678...   \n",
            "6  e443f322884c5440d7f5072f21c5b0e1f0433ba6147471...   \n",
            "\n",
            "                                            sentence sentence_domain  \\\n",
            "0  Madin was a significant figure of post-war Bir...             NaN   \n",
            "2                           No runoff was necessary.             NaN   \n",
            "4                          It was a sickening sight.             NaN   \n",
            "5  It is made by mounting a sidecar to a regular ...             NaN   \n",
            "6  Within his genre, Di Giorgio is respected for ...             NaN   \n",
            "\n",
            "   up_votes  down_votes       age          gender                  accents  \\\n",
            "0         2           0       NaN             NaN  American English Accent   \n",
            "2         2           0     teens     transgender          British English   \n",
            "4         2           0  twenties  male_masculine       Australian English   \n",
            "5         2           0   sixties  male_masculine  American English Accent   \n",
            "6         2           0       NaN             NaN          British English   \n",
            "\n",
            "   variant locale  segment         broader_accents  \n",
            "0      NaN     en      NaN  North American English  \n",
            "2      NaN     en      NaN         British English  \n",
            "4      NaN     en      NaN         British English  \n",
            "5      NaN     en      NaN  North American English  \n",
            "6      NaN     en      NaN         British English  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns from the metadata\n",
        "audio_files = filtered_df['path'].tolist()  # Get the audio file names\n",
        "accents = filtered_df['broader_accents'].tolist()    # Get the corresponding accents\n",
        "\n",
        "# Display the unique accents in the dataset\n",
        "print(\"Unique accents in the dataset:\", set(accents))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkUEft3BVfTp",
        "outputId": "806a2ea7-749b-41b8-e41a-4b258e8b80c5"
      },
      "id": "wkUEft3BVfTp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique accents in the dataset: {'Asian English', 'European English', 'African English', 'North American English', 'British English'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZGBC-vJdTQK",
        "outputId": "6557ae10-7562-4213-d44d-b34421a049ec"
      },
      "id": "qZGBC-vJdTQK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "# Corrected path to processed audio files directory\n",
        "audio_dir = os.path.join(extract_dir, 'en/input_audio_files')\n",
        "\n",
        "# Function to extract MFCC features from an audio file\n",
        "def extract_mfcc(file_path, n_mfcc=13):\n",
        "    y, sr = librosa.load(file_path, sr=16000)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    return np.mean(mfcc.T, axis=0)\n",
        "\n",
        "# Function for augmenting audio data\n",
        "def augment_audio(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=16000)\n",
        "\n",
        "    # Noise Injection\n",
        "    noise = np.random.randn(len(y))\n",
        "    y_noise = y + 0.005 * noise  # Adjust the noise factor as needed\n",
        "\n",
        "    # Time Stretching\n",
        "    y_stretch = librosa.effects.time_stretch(y, rate=1.1)  # Stretch by a factor of 1.1\n",
        "\n",
        "    # Pitch Shifting\n",
        "    y_pitch = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)  # Corrected: Shift pitch up by 2 steps\n",
        "\n",
        "    return [y_noise, y_stretch, y_pitch]\n",
        "\n",
        "# Extract features and apply data augmentation\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for audio_file, accent in zip(audio_files, accents):\n",
        "    try:\n",
        "        file_path = os.path.join(audio_dir, audio_file)  # Corrected single path\n",
        "        # Extract original MFCC features\n",
        "        mfcc_features = extract_mfcc(file_path)\n",
        "        features.append(mfcc_features)\n",
        "        labels.append(accent)\n",
        "\n",
        "        # Apply augmentations and extract MFCC features for each augmented audio\n",
        "        for aug_audio in augment_audio(file_path):\n",
        "            aug_mfcc_features = librosa.feature.mfcc(y=aug_audio, sr=16000, n_mfcc=13)\n",
        "            aug_mfcc_mean = np.mean(aug_mfcc_features.T, axis=0)\n",
        "            features.append(aug_mfcc_mean)\n",
        "            labels.append(accent)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_file}: {e}\")\n",
        "\n",
        "print(\"Feature extraction and augmentation completed!\")\n",
        "\n",
        "# Encode the accent labels to numeric values\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(labels)\n",
        "\n",
        "print(\"Encoded labels:\", encoded_labels[:10])\n",
        "print(\"Classes:\", encoder.classes_)\n",
        "\n",
        "# Split data into training and validation sets (80% training, 20% validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "class AccentDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Create PyTorch Datasets and DataLoaders for training and validation\n",
        "train_dataset = AccentDataset(X_train, y_train)\n",
        "val_dataset = AccentDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Training and Validation DataLoaders are ready!\")\n",
        "\n",
        "class AccentNormalizationModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(AccentNormalizationModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = AccentNormalizationModel(input_size=13, hidden_size=128, num_classes=len(encoder.classes_))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Model is initialized!\")\n",
        "\n",
        "# Training loop with validation\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for features, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(features.unsqueeze(1))  # Add extra dimension for LSTM\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in val_loader:\n",
        "            outputs = model(features.unsqueeze(1))\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "print(\"Training with validation completed!\")\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in data_loader:\n",
        "            outputs = model(features.unsqueeze(1))\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Run evaluation on validation set\n",
        "evaluate_model(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccazXcJGEnOm",
        "outputId": "9bdf2cd1-5be7-4c9f-b031-64e1d3b97a09"
      },
      "id": "ccazXcJGEnOm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction and augmentation completed!\n",
            "Encoded labels: [4 4 4 4 2 2 2 2 2 2]\n",
            "Classes: ['African English' 'Asian English' 'British English' 'European English'\n",
            " 'North American English']\n",
            "Training and Validation DataLoaders are ready!\n",
            "Model is initialized!\n",
            "Epoch [1/10], Loss: 1.0950, Validation Accuracy: 62.79%\n",
            "Epoch [2/10], Loss: 0.6849, Validation Accuracy: 67.92%\n",
            "Epoch [3/10], Loss: 0.8347, Validation Accuracy: 68.93%\n",
            "Epoch [4/10], Loss: 0.8784, Validation Accuracy: 71.24%\n",
            "Epoch [5/10], Loss: 0.7010, Validation Accuracy: 71.39%\n",
            "Epoch [6/10], Loss: 0.9247, Validation Accuracy: 67.56%\n",
            "Epoch [7/10], Loss: 0.4752, Validation Accuracy: 73.19%\n",
            "Epoch [8/10], Loss: 0.5128, Validation Accuracy: 71.03%\n",
            "Epoch [9/10], Loss: 0.6110, Validation Accuracy: 72.69%\n",
            "Epoch [10/10], Loss: 0.5938, Validation Accuracy: 73.55%\n",
            "Training with validation completed!\n",
            "Accuracy: 73.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Function to evaluate the model using different metrics\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, labels in data_loader:\n",
        "            outputs = model(features.unsqueeze(1))\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_labels.extend(labels.tolist())\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    # Generate Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_predictions, target_names=encoder.classes_))\n",
        "\n",
        "    # Generate Confusion Matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_predictions))\n",
        "\n",
        "# Run evaluation on validation set\n",
        "evaluate_model(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHWUO6EvI-0_",
        "outputId": "90815bc4-92e5-43fa-a1a5-b165129f10e9"
      },
      "id": "SHWUO6EvI-0_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.55%\n",
            "\n",
            "Classification Report:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "       African English       0.00      0.00      0.00        11\n",
            "         Asian English       0.81      0.35      0.49       119\n",
            "       British English       0.70      0.70      0.70       451\n",
            "      European English       0.74      0.63      0.68        76\n",
            "North American English       0.75      0.84      0.79       727\n",
            "\n",
            "              accuracy                           0.74      1384\n",
            "             macro avg       0.60      0.51      0.53      1384\n",
            "          weighted avg       0.73      0.74      0.72      1384\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  0   0   4   1   6]\n",
            " [  0  42  26   5  46]\n",
            " [  0   5 316   4 126]\n",
            " [  0   1   4  48  23]\n",
            " [  0   4 104   7 612]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JvF7d6-EI_WF"
      },
      "id": "JvF7d6-EI_WF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}