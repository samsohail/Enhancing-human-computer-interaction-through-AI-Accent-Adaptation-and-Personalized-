{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VHkWdPQKtSE",
        "outputId": "1e78dbff-d831-486b-ab9e-61a5cb53d13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchaudio\n",
        "!pip install audiomentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GJdc4WRLKMS",
        "outputId": "875c6b40-7614-41b4-937b-e897bd46dbaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchaudio) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchaudio) (1.3.0)\n",
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.37.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.26.4)\n",
            "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
            "  Downloading numpy_minmax-0.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
            "  Downloading numpy_rms-0.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.10.2.post1)\n",
            "Collecting scipy<1.13,>=1.4 (from audiomentations)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.8)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2024.8.30)\n",
            "Downloading audiomentations-0.37.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy_minmax-0.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading numpy_rms-0.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17 kB)\n",
            "Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, numpy-rms, numpy-minmax, audiomentations\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed audiomentations-0.37.0 numpy-minmax-0.3.1 numpy-rms-0.4.2 scipy-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "\n",
        "# Step 1: Define Data Augmentation Pipeline\n",
        "augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "    Shift(min_shift=-0.5, max_shift=0.5, p=0.5)\n",
        "])\n",
        "\n",
        "# Custom Dataset for Loading Audio Files with Augmentation\n",
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None, target_length=80000, num_files=100, apply_augmentation=False):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.target_length = target_length\n",
        "        self.apply_augmentation = apply_augmentation\n",
        "        self.audio_files = [f for f in os.listdir(data_dir) if f.endswith('.wav')][:num_files]\n",
        "\n",
        "        if len(self.audio_files) == 0:\n",
        "            raise ValueError(f\"No audio files found in directory: {data_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        wav_path = os.path.join(self.data_dir, self.audio_files[idx])\n",
        "        if not os.path.exists(wav_path):\n",
        "            raise FileNotFoundError(f\"Audio file not found: {wav_path}\")\n",
        "\n",
        "        try:\n",
        "            waveform, sr = torchaudio.load(wav_path)\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error loading audio file: {wav_path}, Error: {e}\")\n",
        "            raise e\n",
        "\n",
        "        # Pad or truncate to the target length\n",
        "        if waveform.shape[1] < self.target_length:\n",
        "            padding = self.target_length - waveform.shape[1]\n",
        "            waveform = F.pad(waveform, (0, padding))\n",
        "        else:\n",
        "            waveform = waveform[:, :self.target_length]\n",
        "\n",
        "        # Apply Augmentation\n",
        "        if self.apply_augmentation:\n",
        "            waveform = augment_audio(waveform)\n",
        "\n",
        "        # Apply normalization if any\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform)\n",
        "\n",
        "        return waveform, self.audio_files[idx]\n",
        "\n",
        "# Function to Apply Augmentation to the Audio\n",
        "def augment_audio(audio):\n",
        "    augmented_samples = augment(samples=audio.numpy(), sample_rate=16000)\n",
        "    return torch.tensor(augmented_samples)\n",
        "\n",
        "# Define Normalization Transform\n",
        "def normalize_waveform(waveform):\n",
        "    return (waveform - waveform.mean()) / waveform.std()\n",
        "\n",
        "# Directories for Data\n",
        "data_dir_A = \"/content/drive/MyDrive/data/extracted_files-3/en/North_American_English_W/\"\n",
        "\n",
        "# Target length for all audio files\n",
        "target_length = 80000\n",
        "\n",
        "# Initialize Dataset with 100 Files and Apply Augmentation\n",
        "dataset_A = SpeechDataset(data_dir_A, transform=normalize_waveform, target_length=target_length, num_files=100, apply_augmentation=True)\n",
        "\n",
        "# Initialize DataLoader\n",
        "dataloader_A = DataLoader(dataset_A, batch_size=1, shuffle=True)\n",
        "\n",
        "# Define VAE with Transformer Components: Encoder, Decoder\n",
        "class TransformerVAE(nn.Module):\n",
        "    def __init__(self, input_dim=80000, latent_dim=64, d_model=512, nhead=8, num_layers=6):\n",
        "        super(TransformerVAE, self).__init__()\n",
        "        self.fc_in = nn.Linear(input_dim, d_model)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead), num_layers=num_layers\n",
        "        )\n",
        "        self.fc_mean = nn.Linear(d_model, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(d_model, latent_dim)\n",
        "        self.fc_out = nn.Linear(latent_dim, input_dim)\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input to (batch_size, seq_length)\n",
        "        x = self.fc_in(x)  # Linear transformation to match d_model\n",
        "        x = x.unsqueeze(1)  # Add sequence length dimension for Transformer\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.mean(dim=1)  # Global average pooling over the sequence length\n",
        "        mean = self.fc_mean(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mean + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.fc_out(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        return self.decode(z), mean, logvar\n",
        "\n",
        "    def loss_function(self, recon_x, x, mean, logvar):\n",
        "        recon_loss = nn.MSELoss()(recon_x, x)\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
        "        return recon_loss + kl_loss\n",
        "\n",
        "# Initialize Models\n",
        "model = TransformerVAE()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
        "\n",
        "# Set device to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to save audio data correctly\n",
        "def save_audio(file_path, audio_tensor, sample_rate=16000):\n",
        "    audio_np = audio_tensor.cpu().detach().numpy().squeeze(0)\n",
        "    audio_np = audio_np / np.max(np.abs(audio_np) + 1e-6)\n",
        "    audio_np = np.clip(audio_np, -1, 1)\n",
        "    audio_np = (audio_np * 32767).astype(np.int16)\n",
        "\n",
        "    if len(audio_np.shape) > 1:\n",
        "        audio_np = audio_np[0]\n",
        "\n",
        "    write(file_path, sample_rate, audio_np)\n",
        "\n",
        "# Training Loop for Transformer-based VAE\n",
        "def train_vae(dataloader_A, num_epochs=5):\n",
        "    filename_mapping_A = {}  # Mapping for evaluation\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        batch_count = 0\n",
        "        for real_A, file_A in dataloader_A:\n",
        "            real_A = real_A.to(device)\n",
        "            batch_count += 1\n",
        "\n",
        "            # Forward pass through VAE\n",
        "            reconstructed_A, mean, logvar = model(real_A)\n",
        "\n",
        "            # Compute Reconstruction Loss\n",
        "            loss = model.loss_function(reconstructed_A, real_A, mean, logvar)\n",
        "\n",
        "            # Update Model\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Save Converted Audio for Evaluation\n",
        "            converted_A_path = f\"/content/drive/MyDrive/data/extracted_files-3/en/vae_converted_epoch_{epoch}/{file_A[0]}\"\n",
        "            os.makedirs(os.path.dirname(converted_A_path), exist_ok=True)\n",
        "\n",
        "            save_audio(converted_A_path, reconstructed_A, sample_rate=16000)\n",
        "\n",
        "            # Update Mappings for Evaluation\n",
        "            filename_mapping_A[file_A[0]] = file_A[0]  # Map original to new\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_count}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed.\")\n",
        "        evaluate_vae(epoch, filename_mapping_A)\n",
        "\n",
        "    print(\"Training completed successfully!\")\n",
        "\n",
        "# Evaluation function for VAE\n",
        "def evaluate_vae(epoch, mapping_A):\n",
        "    original_dir_A = \"/content/drive/MyDrive/data/extracted_files-3/en/North_American_English_W/\"\n",
        "    converted_dir_A = f\"/content/drive/MyDrive/data/extracted_files-3/en/vae_converted_epoch_{epoch}\"\n",
        "\n",
        "    print(f\"Evaluating VAE performance after Epoch {epoch+1}\")\n",
        "\n",
        "    # Load Wav2Vec2 model and tokenizer from HuggingFace\n",
        "    asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    asr_model.eval()\n",
        "\n",
        "    evaluate_metrics(original_dir=original_dir_A, converted_dir=converted_dir_A, mapping=mapping_A, asr_model=asr_model, tokenizer=tokenizer)\n",
        "\n",
        "# Function to Compute MCD (Placeholder)\n",
        "def compute_mcd(orig_audio, conv_audio):\n",
        "    return np.random.random()\n",
        "\n",
        "# Evaluation function for Mean Mel-Cepstral Distortion (MCD) and WER\n",
        "def evaluate_metrics(original_dir, converted_dir, mapping, asr_model, tokenizer):\n",
        "    mcd_scores = []\n",
        "    wer_scores = []\n",
        "\n",
        "    for orig_file, conv_file in mapping.items():\n",
        "        orig_path = os.path.join(original_dir, orig_file)\n",
        "        conv_path = os.path.join(converted_dir, conv_file)\n",
        "\n",
        "        if not os.path.exists(orig_path):\n",
        "            print(f\"Original file not found: {orig_path}\")\n",
        "            continue\n",
        "        if not os.path.exists(conv_path):\n",
        "            print(f\"Converted file not found: {conv_path}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            orig_audio, _ = torchaudio.load(orig_path)\n",
        "            conv_audio, _ = torchaudio.load(conv_path)\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error loading audio files. Original: {orig_path}, Converted: {conv_path}, Error: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Compute MCD\n",
        "        mcd_score = compute_mcd(orig_audio, conv_audio)\n",
        "        mcd_scores.append(mcd_score)\n",
        "\n",
        "\n",
        "    if mcd_scores:\n",
        "        mean_mcd = np.mean(mcd_scores)\n",
        "        print(f\"Mean MCD: {mean_mcd:.4f}\")\n",
        "    else:\n",
        "        print(\"No valid MCD scores computed due to missing or corrupt files.\")\n",
        "\n",
        "\n",
        "# Start Training for VAE\n",
        "train_vae(dataloader_A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "navjB5xwLIZn",
        "outputId": "7ff51fae-81e9-4fd3-8779-8c8e4a581a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([1, 1, 80000])) that is different to the input size (torch.Size([1, 80000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [1], Loss: 16.7536\n",
            "Epoch [1/5], Batch [2], Loss: 23.0881\n",
            "Epoch [1/5], Batch [3], Loss: 20.9909\n",
            "Epoch [1/5], Batch [4], Loss: 16.4448\n",
            "Epoch [1/5], Batch [5], Loss: 17.5795\n",
            "Epoch [1/5], Batch [6], Loss: 10.7707\n",
            "Epoch [1/5], Batch [7], Loss: 13.0960\n",
            "Epoch [1/5], Batch [8], Loss: 13.8197\n",
            "Epoch [1/5], Batch [9], Loss: 6.6172\n",
            "Epoch [1/5], Batch [10], Loss: 12.4846\n",
            "Epoch [1/5], Batch [11], Loss: 6.2364\n",
            "Epoch [1/5], Batch [12], Loss: 5.6347\n",
            "Epoch [1/5], Batch [13], Loss: 10.7249\n",
            "Epoch [1/5], Batch [14], Loss: 5.1101\n",
            "Epoch [1/5], Batch [15], Loss: 4.8211\n",
            "Epoch [1/5], Batch [16], Loss: 3.4947\n",
            "Epoch [1/5], Batch [17], Loss: 4.4625\n",
            "Epoch [1/5], Batch [18], Loss: 4.4735\n",
            "Epoch [1/5], Batch [19], Loss: 4.0209\n",
            "Epoch [1/5], Batch [20], Loss: 3.1144\n",
            "Epoch [1/5], Batch [21], Loss: 3.1910\n",
            "Epoch [1/5], Batch [22], Loss: 3.0468\n",
            "Epoch [1/5], Batch [23], Loss: 3.0244\n",
            "Epoch [1/5], Batch [24], Loss: 3.0435\n",
            "Epoch [1/5], Batch [25], Loss: 2.6453\n",
            "Epoch [1/5], Batch [26], Loss: 2.8086\n",
            "Epoch [1/5], Batch [27], Loss: 2.4779\n",
            "Epoch [1/5], Batch [28], Loss: 2.6819\n",
            "Epoch [1/5], Batch [29], Loss: 2.7071\n",
            "Epoch [1/5], Batch [30], Loss: 2.8643\n",
            "Epoch [1/5], Batch [31], Loss: 2.5612\n",
            "Epoch [1/5], Batch [32], Loss: 2.8176\n",
            "Epoch [1/5], Batch [33], Loss: 2.8703\n",
            "Epoch [1/5], Batch [34], Loss: 2.5965\n",
            "Epoch [1/5], Batch [35], Loss: 2.5356\n",
            "Epoch [1/5], Batch [36], Loss: 2.3814\n",
            "Epoch [1/5], Batch [37], Loss: 2.5821\n",
            "Epoch [1/5], Batch [38], Loss: 2.8316\n",
            "Epoch [1/5], Batch [39], Loss: 2.3910\n",
            "Epoch [1/5], Batch [40], Loss: 2.4916\n",
            "Epoch [1/5], Batch [41], Loss: 2.7587\n",
            "Epoch [1/5], Batch [42], Loss: 2.3400\n",
            "Epoch [1/5], Batch [43], Loss: 2.2445\n",
            "Epoch [1/5], Batch [44], Loss: 2.5712\n",
            "Epoch [1/5], Batch [45], Loss: 2.4844\n",
            "Epoch [1/5], Batch [46], Loss: 2.4442\n",
            "Epoch [1/5], Batch [47], Loss: 2.3436\n",
            "Epoch [1/5], Batch [48], Loss: 2.9120\n",
            "Epoch [1/5], Batch [49], Loss: 2.4377\n",
            "Epoch [1/5], Batch [50], Loss: 2.2318\n",
            "Epoch [1/5], Batch [51], Loss: 2.0837\n",
            "Epoch [1/5], Batch [52], Loss: 2.1333\n",
            "Epoch [1/5], Batch [53], Loss: 2.6957\n",
            "Epoch [1/5], Batch [54], Loss: 2.4076\n",
            "Epoch [1/5], Batch [55], Loss: 2.5392\n",
            "Epoch [1/5], Batch [56], Loss: 2.4468\n",
            "Epoch [1/5], Batch [57], Loss: 2.2099\n",
            "Epoch [1/5], Batch [58], Loss: 2.4402\n",
            "Epoch [1/5], Batch [59], Loss: 2.2018\n",
            "Epoch [1/5], Batch [60], Loss: 2.4417\n",
            "Epoch [1/5], Batch [61], Loss: 2.3885\n",
            "Epoch [1/5], Batch [62], Loss: 2.5699\n",
            "Epoch [1/5], Batch [63], Loss: 2.2443\n",
            "Epoch [1/5], Batch [64], Loss: 2.6299\n",
            "Epoch [1/5], Batch [65], Loss: 2.0949\n",
            "Epoch [1/5], Batch [66], Loss: 2.1474\n",
            "Epoch [1/5], Batch [67], Loss: 2.5176\n",
            "Epoch [1/5], Batch [68], Loss: 2.3251\n",
            "Epoch [1/5], Batch [69], Loss: 2.1974\n",
            "Epoch [1/5], Batch [70], Loss: 2.3951\n",
            "Epoch [1/5], Batch [71], Loss: 2.6828\n",
            "Epoch [1/5], Batch [72], Loss: 2.5561\n",
            "Epoch [1/5], Batch [73], Loss: 2.4196\n",
            "Epoch [1/5], Batch [74], Loss: 2.4933\n",
            "Epoch [1/5], Batch [75], Loss: 2.3576\n",
            "Epoch [1/5], Batch [76], Loss: 2.1604\n",
            "Epoch [1/5], Batch [77], Loss: 2.2424\n",
            "Epoch [1/5], Batch [78], Loss: 2.0693\n",
            "Epoch [1/5], Batch [79], Loss: 2.3388\n",
            "Epoch [1/5], Batch [80], Loss: 2.1274\n",
            "Epoch [1/5], Batch [81], Loss: 2.0777\n",
            "Epoch [1/5], Batch [82], Loss: 2.4030\n",
            "Epoch [1/5], Batch [83], Loss: 2.3788\n",
            "Epoch [1/5], Batch [84], Loss: 2.2459\n",
            "Epoch [1/5], Batch [85], Loss: 2.1364\n",
            "Epoch [1/5], Batch [86], Loss: 2.4181\n",
            "Epoch [1/5], Batch [87], Loss: 2.4749\n",
            "Epoch [1/5], Batch [88], Loss: 2.3665\n",
            "Epoch [1/5], Batch [89], Loss: 2.1692\n",
            "Epoch [1/5], Batch [90], Loss: 2.0798\n",
            "Epoch [1/5], Batch [91], Loss: 2.4496\n",
            "Epoch [1/5], Batch [92], Loss: 2.5593\n",
            "Epoch [1/5], Batch [93], Loss: 2.3659\n",
            "Epoch [1/5], Batch [94], Loss: 2.2837\n",
            "Epoch [1/5], Batch [95], Loss: 2.1032\n",
            "Epoch [1/5], Batch [96], Loss: 2.1235\n",
            "Epoch [1/5], Batch [97], Loss: 2.8738\n",
            "Epoch [1/5], Batch [98], Loss: 2.2574\n",
            "Epoch [1/5], Batch [99], Loss: 2.3455\n",
            "Epoch [1/5], Batch [100], Loss: 2.1979\n",
            "Epoch [1/5] completed.\n",
            "Evaluating VAE performance after Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCD: 0.5068\n",
            "Epoch [2/5], Batch [1], Loss: 2.0945\n",
            "Epoch [2/5], Batch [2], Loss: 2.1077\n",
            "Epoch [2/5], Batch [3], Loss: 2.3619\n",
            "Epoch [2/5], Batch [4], Loss: 2.1151\n",
            "Epoch [2/5], Batch [5], Loss: 2.3647\n",
            "Epoch [2/5], Batch [6], Loss: 2.4124\n",
            "Epoch [2/5], Batch [7], Loss: 1.9996\n",
            "Epoch [2/5], Batch [8], Loss: 2.4676\n",
            "Epoch [2/5], Batch [9], Loss: 2.4489\n",
            "Epoch [2/5], Batch [10], Loss: 2.0158\n",
            "Epoch [2/5], Batch [11], Loss: 2.2881\n",
            "Epoch [2/5], Batch [12], Loss: 2.5560\n",
            "Epoch [2/5], Batch [13], Loss: 2.0537\n",
            "Epoch [2/5], Batch [14], Loss: 2.0618\n",
            "Epoch [2/5], Batch [15], Loss: 2.1426\n",
            "Epoch [2/5], Batch [16], Loss: 2.1696\n",
            "Epoch [2/5], Batch [17], Loss: 2.2122\n",
            "Epoch [2/5], Batch [18], Loss: 2.2209\n",
            "Epoch [2/5], Batch [19], Loss: 2.2541\n",
            "Epoch [2/5], Batch [20], Loss: 2.1755\n",
            "Epoch [2/5], Batch [21], Loss: 2.2046\n",
            "Epoch [2/5], Batch [22], Loss: 2.2963\n",
            "Epoch [2/5], Batch [23], Loss: 2.2795\n",
            "Epoch [2/5], Batch [24], Loss: 2.2208\n",
            "Epoch [2/5], Batch [25], Loss: 2.0877\n",
            "Epoch [2/5], Batch [26], Loss: 2.1373\n",
            "Epoch [2/5], Batch [27], Loss: 2.1355\n",
            "Epoch [2/5], Batch [28], Loss: 2.4733\n",
            "Epoch [2/5], Batch [29], Loss: 2.5478\n",
            "Epoch [2/5], Batch [30], Loss: 2.6836\n",
            "Epoch [2/5], Batch [31], Loss: 2.0996\n",
            "Epoch [2/5], Batch [32], Loss: 2.2662\n",
            "Epoch [2/5], Batch [33], Loss: 2.3407\n",
            "Epoch [2/5], Batch [34], Loss: 2.5330\n",
            "Epoch [2/5], Batch [35], Loss: 2.2065\n",
            "Epoch [2/5], Batch [36], Loss: 2.4242\n",
            "Epoch [2/5], Batch [37], Loss: 2.2100\n",
            "Epoch [2/5], Batch [38], Loss: 2.2965\n",
            "Epoch [2/5], Batch [39], Loss: 2.0787\n",
            "Epoch [2/5], Batch [40], Loss: 2.1880\n",
            "Epoch [2/5], Batch [41], Loss: 2.0067\n",
            "Epoch [2/5], Batch [42], Loss: 2.2253\n",
            "Epoch [2/5], Batch [43], Loss: 2.2035\n",
            "Epoch [2/5], Batch [44], Loss: 1.9930\n",
            "Epoch [2/5], Batch [45], Loss: 2.1440\n",
            "Epoch [2/5], Batch [46], Loss: 1.9723\n",
            "Epoch [2/5], Batch [47], Loss: 2.4834\n",
            "Epoch [2/5], Batch [48], Loss: 2.2824\n",
            "Epoch [2/5], Batch [49], Loss: 2.6466\n",
            "Epoch [2/5], Batch [50], Loss: 2.6208\n",
            "Epoch [2/5], Batch [51], Loss: 2.2222\n",
            "Epoch [2/5], Batch [52], Loss: 2.4016\n",
            "Epoch [2/5], Batch [53], Loss: 2.3045\n",
            "Epoch [2/5], Batch [54], Loss: 2.2051\n",
            "Epoch [2/5], Batch [55], Loss: 2.1546\n",
            "Epoch [2/5], Batch [56], Loss: 2.1103\n",
            "Epoch [2/5], Batch [57], Loss: 2.3546\n",
            "Epoch [2/5], Batch [58], Loss: 2.2076\n",
            "Epoch [2/5], Batch [59], Loss: 2.2667\n",
            "Epoch [2/5], Batch [60], Loss: 2.0392\n",
            "Epoch [2/5], Batch [61], Loss: 2.0903\n",
            "Epoch [2/5], Batch [62], Loss: 2.1595\n",
            "Epoch [2/5], Batch [63], Loss: 2.3409\n",
            "Epoch [2/5], Batch [64], Loss: 2.1506\n",
            "Epoch [2/5], Batch [65], Loss: 2.3213\n",
            "Epoch [2/5], Batch [66], Loss: 2.1437\n",
            "Epoch [2/5], Batch [67], Loss: 2.0541\n",
            "Epoch [2/5], Batch [68], Loss: 2.2665\n",
            "Epoch [2/5], Batch [69], Loss: 2.0533\n",
            "Epoch [2/5], Batch [70], Loss: 2.2567\n",
            "Epoch [2/5], Batch [71], Loss: 2.6422\n",
            "Epoch [2/5], Batch [72], Loss: 2.0903\n",
            "Epoch [2/5], Batch [73], Loss: 2.2220\n",
            "Epoch [2/5], Batch [74], Loss: 2.0285\n",
            "Epoch [2/5], Batch [75], Loss: 1.9092\n",
            "Epoch [2/5], Batch [76], Loss: 2.0717\n",
            "Epoch [2/5], Batch [77], Loss: 2.0000\n",
            "Epoch [2/5], Batch [78], Loss: 2.3585\n",
            "Epoch [2/5], Batch [79], Loss: 2.4754\n",
            "Epoch [2/5], Batch [80], Loss: 2.1389\n",
            "Epoch [2/5], Batch [81], Loss: 2.2562\n",
            "Epoch [2/5], Batch [82], Loss: 2.2388\n",
            "Epoch [2/5], Batch [83], Loss: 2.2567\n",
            "Epoch [2/5], Batch [84], Loss: 1.8221\n",
            "Epoch [2/5], Batch [85], Loss: 1.9438\n",
            "Epoch [2/5], Batch [86], Loss: 1.9601\n",
            "Epoch [2/5], Batch [87], Loss: 2.0402\n",
            "Epoch [2/5], Batch [88], Loss: 2.0820\n",
            "Epoch [2/5], Batch [89], Loss: 2.0052\n",
            "Epoch [2/5], Batch [90], Loss: 2.2190\n",
            "Epoch [2/5], Batch [91], Loss: 2.4162\n",
            "Epoch [2/5], Batch [92], Loss: 2.0328\n",
            "Epoch [2/5], Batch [93], Loss: 1.9377\n",
            "Epoch [2/5], Batch [94], Loss: 2.0030\n",
            "Epoch [2/5], Batch [95], Loss: 2.1930\n",
            "Epoch [2/5], Batch [96], Loss: 1.9636\n",
            "Epoch [2/5], Batch [97], Loss: 2.1578\n",
            "Epoch [2/5], Batch [98], Loss: 2.2071\n",
            "Epoch [2/5], Batch [99], Loss: 2.2447\n",
            "Epoch [2/5], Batch [100], Loss: 2.2421\n",
            "Epoch [2/5] completed.\n",
            "Evaluating VAE performance after Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCD: 0.4764\n",
            "Epoch [3/5], Batch [1], Loss: 2.3282\n",
            "Epoch [3/5], Batch [2], Loss: 2.3881\n",
            "Epoch [3/5], Batch [3], Loss: 2.4003\n",
            "Epoch [3/5], Batch [4], Loss: 2.0933\n",
            "Epoch [3/5], Batch [5], Loss: 2.2804\n",
            "Epoch [3/5], Batch [6], Loss: 2.0237\n",
            "Epoch [3/5], Batch [7], Loss: 2.1199\n",
            "Epoch [3/5], Batch [8], Loss: 2.3370\n",
            "Epoch [3/5], Batch [9], Loss: 2.4247\n",
            "Epoch [3/5], Batch [10], Loss: 1.9710\n",
            "Epoch [3/5], Batch [11], Loss: 1.9335\n",
            "Epoch [3/5], Batch [12], Loss: 2.0873\n",
            "Epoch [3/5], Batch [13], Loss: 2.0807\n",
            "Epoch [3/5], Batch [14], Loss: 2.0557\n",
            "Epoch [3/5], Batch [15], Loss: 2.2736\n",
            "Epoch [3/5], Batch [16], Loss: 2.0743\n",
            "Epoch [3/5], Batch [17], Loss: 1.9128\n",
            "Epoch [3/5], Batch [18], Loss: 2.2234\n",
            "Epoch [3/5], Batch [19], Loss: 2.0809\n",
            "Epoch [3/5], Batch [20], Loss: 2.2078\n",
            "Epoch [3/5], Batch [21], Loss: 2.1399\n",
            "Epoch [3/5], Batch [22], Loss: 2.1775\n",
            "Epoch [3/5], Batch [23], Loss: 2.1124\n",
            "Epoch [3/5], Batch [24], Loss: 2.0715\n",
            "Epoch [3/5], Batch [25], Loss: 2.3158\n",
            "Epoch [3/5], Batch [26], Loss: 2.2649\n",
            "Epoch [3/5], Batch [27], Loss: 1.9170\n",
            "Epoch [3/5], Batch [28], Loss: 1.9879\n",
            "Epoch [3/5], Batch [29], Loss: 2.0458\n",
            "Epoch [3/5], Batch [30], Loss: 1.8958\n",
            "Epoch [3/5], Batch [31], Loss: 2.3078\n",
            "Epoch [3/5], Batch [32], Loss: 2.3602\n",
            "Epoch [3/5], Batch [33], Loss: 2.2050\n",
            "Epoch [3/5], Batch [34], Loss: 1.8432\n",
            "Epoch [3/5], Batch [35], Loss: 1.9265\n",
            "Epoch [3/5], Batch [36], Loss: 2.1643\n",
            "Epoch [3/5], Batch [37], Loss: 2.1315\n",
            "Epoch [3/5], Batch [38], Loss: 2.2259\n",
            "Epoch [3/5], Batch [39], Loss: 2.0143\n",
            "Epoch [3/5], Batch [40], Loss: 2.3182\n",
            "Epoch [3/5], Batch [41], Loss: 2.1450\n",
            "Epoch [3/5], Batch [42], Loss: 2.0770\n",
            "Epoch [3/5], Batch [43], Loss: 2.2225\n",
            "Epoch [3/5], Batch [44], Loss: 1.9442\n",
            "Epoch [3/5], Batch [45], Loss: 2.0906\n",
            "Epoch [3/5], Batch [46], Loss: 2.1664\n",
            "Epoch [3/5], Batch [47], Loss: 2.3125\n",
            "Epoch [3/5], Batch [48], Loss: 1.9646\n",
            "Epoch [3/5], Batch [49], Loss: 2.0164\n",
            "Epoch [3/5], Batch [50], Loss: 2.2473\n",
            "Epoch [3/5], Batch [51], Loss: 2.2942\n",
            "Epoch [3/5], Batch [52], Loss: 2.3678\n",
            "Epoch [3/5], Batch [53], Loss: 2.2643\n",
            "Epoch [3/5], Batch [54], Loss: 2.4786\n",
            "Epoch [3/5], Batch [55], Loss: 2.3316\n",
            "Epoch [3/5], Batch [56], Loss: 2.0145\n",
            "Epoch [3/5], Batch [57], Loss: 2.2577\n",
            "Epoch [3/5], Batch [58], Loss: 1.9338\n",
            "Epoch [3/5], Batch [59], Loss: 2.0043\n",
            "Epoch [3/5], Batch [60], Loss: 2.2810\n",
            "Epoch [3/5], Batch [61], Loss: 2.2069\n",
            "Epoch [3/5], Batch [62], Loss: 1.9613\n",
            "Epoch [3/5], Batch [63], Loss: 2.3036\n",
            "Epoch [3/5], Batch [64], Loss: 2.0049\n",
            "Epoch [3/5], Batch [65], Loss: 2.0224\n",
            "Epoch [3/5], Batch [66], Loss: 2.1361\n",
            "Epoch [3/5], Batch [67], Loss: 2.2434\n",
            "Epoch [3/5], Batch [68], Loss: 2.0108\n",
            "Epoch [3/5], Batch [69], Loss: 1.8241\n",
            "Epoch [3/5], Batch [70], Loss: 2.0423\n",
            "Epoch [3/5], Batch [71], Loss: 2.4166\n",
            "Epoch [3/5], Batch [72], Loss: 1.9692\n",
            "Epoch [3/5], Batch [73], Loss: 1.9953\n",
            "Epoch [3/5], Batch [74], Loss: 2.0999\n",
            "Epoch [3/5], Batch [75], Loss: 2.2590\n",
            "Epoch [3/5], Batch [76], Loss: 2.2925\n",
            "Epoch [3/5], Batch [77], Loss: 2.1858\n",
            "Epoch [3/5], Batch [78], Loss: 2.1310\n",
            "Epoch [3/5], Batch [79], Loss: 2.1203\n",
            "Epoch [3/5], Batch [80], Loss: 1.8864\n",
            "Epoch [3/5], Batch [81], Loss: 2.1738\n",
            "Epoch [3/5], Batch [82], Loss: 1.9097\n",
            "Epoch [3/5], Batch [83], Loss: 1.9004\n",
            "Epoch [3/5], Batch [84], Loss: 1.9674\n",
            "Epoch [3/5], Batch [85], Loss: 2.3295\n",
            "Epoch [3/5], Batch [86], Loss: 1.8546\n",
            "Epoch [3/5], Batch [87], Loss: 2.0070\n",
            "Epoch [3/5], Batch [88], Loss: 1.8978\n",
            "Epoch [3/5], Batch [89], Loss: 1.9835\n",
            "Epoch [3/5], Batch [90], Loss: 1.9489\n",
            "Epoch [3/5], Batch [91], Loss: 2.0635\n",
            "Epoch [3/5], Batch [92], Loss: 2.1161\n",
            "Epoch [3/5], Batch [93], Loss: 1.9326\n",
            "Epoch [3/5], Batch [94], Loss: 2.2017\n",
            "Epoch [3/5], Batch [95], Loss: 2.0077\n",
            "Epoch [3/5], Batch [96], Loss: 1.9344\n",
            "Epoch [3/5], Batch [97], Loss: 2.1847\n",
            "Epoch [3/5], Batch [98], Loss: 2.3500\n",
            "Epoch [3/5], Batch [99], Loss: 1.9609\n",
            "Epoch [3/5], Batch [100], Loss: 2.1553\n",
            "Epoch [3/5] completed.\n",
            "Evaluating VAE performance after Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCD: 0.4794\n",
            "Epoch [4/5], Batch [1], Loss: 2.0208\n",
            "Epoch [4/5], Batch [2], Loss: 1.7928\n",
            "Epoch [4/5], Batch [3], Loss: 2.1036\n",
            "Epoch [4/5], Batch [4], Loss: 2.1246\n",
            "Epoch [4/5], Batch [5], Loss: 1.9031\n",
            "Epoch [4/5], Batch [6], Loss: 2.0710\n",
            "Epoch [4/5], Batch [7], Loss: 2.0033\n",
            "Epoch [4/5], Batch [8], Loss: 2.2478\n",
            "Epoch [4/5], Batch [9], Loss: 2.0887\n",
            "Epoch [4/5], Batch [10], Loss: 2.0267\n",
            "Epoch [4/5], Batch [11], Loss: 1.9358\n",
            "Epoch [4/5], Batch [12], Loss: 2.0599\n",
            "Epoch [4/5], Batch [13], Loss: 2.0222\n",
            "Epoch [4/5], Batch [14], Loss: 2.0552\n",
            "Epoch [4/5], Batch [15], Loss: 2.2446\n",
            "Epoch [4/5], Batch [16], Loss: 1.8394\n",
            "Epoch [4/5], Batch [17], Loss: 1.9930\n",
            "Epoch [4/5], Batch [18], Loss: 2.0111\n",
            "Epoch [4/5], Batch [19], Loss: 2.0570\n",
            "Epoch [4/5], Batch [20], Loss: 2.2422\n",
            "Epoch [4/5], Batch [21], Loss: 1.9759\n",
            "Epoch [4/5], Batch [22], Loss: 2.6287\n",
            "Epoch [4/5], Batch [23], Loss: 2.0961\n",
            "Epoch [4/5], Batch [24], Loss: 2.1728\n",
            "Epoch [4/5], Batch [25], Loss: 2.3226\n",
            "Epoch [4/5], Batch [26], Loss: 2.2980\n",
            "Epoch [4/5], Batch [27], Loss: 2.0680\n",
            "Epoch [4/5], Batch [28], Loss: 2.1775\n",
            "Epoch [4/5], Batch [29], Loss: 2.1483\n",
            "Epoch [4/5], Batch [30], Loss: 2.0681\n",
            "Epoch [4/5], Batch [31], Loss: 2.2309\n",
            "Epoch [4/5], Batch [32], Loss: 2.3449\n",
            "Epoch [4/5], Batch [33], Loss: 2.0973\n",
            "Epoch [4/5], Batch [34], Loss: 2.0083\n",
            "Epoch [4/5], Batch [35], Loss: 1.9729\n",
            "Epoch [4/5], Batch [36], Loss: 2.0130\n",
            "Epoch [4/5], Batch [37], Loss: 2.2806\n",
            "Epoch [4/5], Batch [38], Loss: 2.0661\n",
            "Epoch [4/5], Batch [39], Loss: 2.1134\n",
            "Epoch [4/5], Batch [40], Loss: 2.0970\n",
            "Epoch [4/5], Batch [41], Loss: 2.2687\n",
            "Epoch [4/5], Batch [42], Loss: 2.0736\n",
            "Epoch [4/5], Batch [43], Loss: 1.7450\n",
            "Epoch [4/5], Batch [44], Loss: 2.1705\n",
            "Epoch [4/5], Batch [45], Loss: 2.1466\n",
            "Epoch [4/5], Batch [46], Loss: 2.1421\n",
            "Epoch [4/5], Batch [47], Loss: 2.4394\n",
            "Epoch [4/5], Batch [48], Loss: 1.9747\n",
            "Epoch [4/5], Batch [49], Loss: 2.0740\n",
            "Epoch [4/5], Batch [50], Loss: 2.0860\n",
            "Epoch [4/5], Batch [51], Loss: 2.0451\n",
            "Epoch [4/5], Batch [52], Loss: 1.9886\n",
            "Epoch [4/5], Batch [53], Loss: 2.0966\n",
            "Epoch [4/5], Batch [54], Loss: 2.0526\n",
            "Epoch [4/5], Batch [55], Loss: 2.0169\n",
            "Epoch [4/5], Batch [56], Loss: 2.0169\n",
            "Epoch [4/5], Batch [57], Loss: 2.0048\n",
            "Epoch [4/5], Batch [58], Loss: 2.1985\n",
            "Epoch [4/5], Batch [59], Loss: 1.9391\n",
            "Epoch [4/5], Batch [60], Loss: 1.9745\n",
            "Epoch [4/5], Batch [61], Loss: 1.9107\n",
            "Epoch [4/5], Batch [62], Loss: 1.7176\n",
            "Epoch [4/5], Batch [63], Loss: 2.2457\n",
            "Epoch [4/5], Batch [64], Loss: 1.8708\n",
            "Epoch [4/5], Batch [65], Loss: 1.9121\n",
            "Epoch [4/5], Batch [66], Loss: 2.2110\n",
            "Epoch [4/5], Batch [67], Loss: 1.8257\n",
            "Epoch [4/5], Batch [68], Loss: 2.1867\n",
            "Epoch [4/5], Batch [69], Loss: 2.3819\n",
            "Epoch [4/5], Batch [70], Loss: 2.1980\n",
            "Epoch [4/5], Batch [71], Loss: 2.0074\n",
            "Epoch [4/5], Batch [72], Loss: 1.9518\n",
            "Epoch [4/5], Batch [73], Loss: 2.0728\n",
            "Epoch [4/5], Batch [74], Loss: 1.8886\n",
            "Epoch [4/5], Batch [75], Loss: 1.9866\n",
            "Epoch [4/5], Batch [76], Loss: 2.1665\n",
            "Epoch [4/5], Batch [77], Loss: 2.1619\n",
            "Epoch [4/5], Batch [78], Loss: 2.0588\n",
            "Epoch [4/5], Batch [79], Loss: 2.0265\n",
            "Epoch [4/5], Batch [80], Loss: 1.9372\n",
            "Epoch [4/5], Batch [81], Loss: 1.8835\n",
            "Epoch [4/5], Batch [82], Loss: 2.0856\n",
            "Epoch [4/5], Batch [83], Loss: 2.2771\n",
            "Epoch [4/5], Batch [84], Loss: 2.0646\n",
            "Epoch [4/5], Batch [85], Loss: 2.0219\n",
            "Epoch [4/5], Batch [86], Loss: 2.0868\n",
            "Epoch [4/5], Batch [87], Loss: 2.0110\n",
            "Epoch [4/5], Batch [88], Loss: 1.9753\n",
            "Epoch [4/5], Batch [89], Loss: 2.0911\n",
            "Epoch [4/5], Batch [90], Loss: 1.9683\n",
            "Epoch [4/5], Batch [91], Loss: 2.0177\n",
            "Epoch [4/5], Batch [92], Loss: 2.1589\n",
            "Epoch [4/5], Batch [93], Loss: 1.9493\n",
            "Epoch [4/5], Batch [94], Loss: 2.0039\n",
            "Epoch [4/5], Batch [95], Loss: 2.2100\n",
            "Epoch [4/5], Batch [96], Loss: 2.0338\n",
            "Epoch [4/5], Batch [97], Loss: 2.0018\n",
            "Epoch [4/5], Batch [98], Loss: 2.2685\n",
            "Epoch [4/5], Batch [99], Loss: 2.2726\n",
            "Epoch [4/5], Batch [100], Loss: 2.0670\n",
            "Epoch [4/5] completed.\n",
            "Evaluating VAE performance after Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCD: 0.5508\n",
            "Epoch [5/5], Batch [1], Loss: 2.2024\n",
            "Epoch [5/5], Batch [2], Loss: 1.9032\n",
            "Epoch [5/5], Batch [3], Loss: 2.2313\n",
            "Epoch [5/5], Batch [4], Loss: 2.1101\n",
            "Epoch [5/5], Batch [5], Loss: 2.1686\n",
            "Epoch [5/5], Batch [6], Loss: 2.2402\n",
            "Epoch [5/5], Batch [7], Loss: 2.0763\n",
            "Epoch [5/5], Batch [8], Loss: 1.8953\n",
            "Epoch [5/5], Batch [9], Loss: 2.1071\n",
            "Epoch [5/5], Batch [10], Loss: 1.8374\n",
            "Epoch [5/5], Batch [11], Loss: 1.9385\n",
            "Epoch [5/5], Batch [12], Loss: 1.8549\n",
            "Epoch [5/5], Batch [13], Loss: 1.9775\n",
            "Epoch [5/5], Batch [14], Loss: 1.8536\n",
            "Epoch [5/5], Batch [15], Loss: 1.9347\n",
            "Epoch [5/5], Batch [16], Loss: 2.0964\n",
            "Epoch [5/5], Batch [17], Loss: 2.0638\n",
            "Epoch [5/5], Batch [18], Loss: 1.7773\n",
            "Epoch [5/5], Batch [19], Loss: 1.9139\n",
            "Epoch [5/5], Batch [20], Loss: 1.9367\n",
            "Epoch [5/5], Batch [21], Loss: 1.8481\n",
            "Epoch [5/5], Batch [22], Loss: 2.2183\n",
            "Epoch [5/5], Batch [23], Loss: 1.9093\n",
            "Epoch [5/5], Batch [24], Loss: 2.0522\n",
            "Epoch [5/5], Batch [25], Loss: 2.1442\n",
            "Epoch [5/5], Batch [26], Loss: 2.1221\n",
            "Epoch [5/5], Batch [27], Loss: 1.8978\n",
            "Epoch [5/5], Batch [28], Loss: 2.0159\n",
            "Epoch [5/5], Batch [29], Loss: 2.0550\n",
            "Epoch [5/5], Batch [30], Loss: 1.7355\n",
            "Epoch [5/5], Batch [31], Loss: 1.9531\n",
            "Epoch [5/5], Batch [32], Loss: 1.7733\n",
            "Epoch [5/5], Batch [33], Loss: 1.8806\n",
            "Epoch [5/5], Batch [34], Loss: 2.1047\n",
            "Epoch [5/5], Batch [35], Loss: 2.1279\n",
            "Epoch [5/5], Batch [36], Loss: 1.8342\n",
            "Epoch [5/5], Batch [37], Loss: 1.8859\n",
            "Epoch [5/5], Batch [38], Loss: 1.8676\n",
            "Epoch [5/5], Batch [39], Loss: 1.8540\n",
            "Epoch [5/5], Batch [40], Loss: 1.8585\n",
            "Epoch [5/5], Batch [41], Loss: 2.3747\n",
            "Epoch [5/5], Batch [42], Loss: 2.1105\n",
            "Epoch [5/5], Batch [43], Loss: 2.0338\n",
            "Epoch [5/5], Batch [44], Loss: 1.9322\n",
            "Epoch [5/5], Batch [45], Loss: 1.9928\n",
            "Epoch [5/5], Batch [46], Loss: 2.1926\n",
            "Epoch [5/5], Batch [47], Loss: 1.8707\n",
            "Epoch [5/5], Batch [48], Loss: 1.6785\n",
            "Epoch [5/5], Batch [49], Loss: 1.8894\n",
            "Epoch [5/5], Batch [50], Loss: 2.1399\n",
            "Epoch [5/5], Batch [51], Loss: 1.8327\n",
            "Epoch [5/5], Batch [52], Loss: 1.8913\n",
            "Epoch [5/5], Batch [53], Loss: 2.0063\n",
            "Epoch [5/5], Batch [54], Loss: 1.8489\n",
            "Epoch [5/5], Batch [55], Loss: 2.1893\n",
            "Epoch [5/5], Batch [56], Loss: 1.9148\n",
            "Epoch [5/5], Batch [57], Loss: 2.0108\n",
            "Epoch [5/5], Batch [58], Loss: 1.9573\n",
            "Epoch [5/5], Batch [59], Loss: 1.9345\n",
            "Epoch [5/5], Batch [60], Loss: 1.9601\n",
            "Epoch [5/5], Batch [61], Loss: 2.1061\n",
            "Epoch [5/5], Batch [62], Loss: 2.0124\n",
            "Epoch [5/5], Batch [63], Loss: 2.1946\n",
            "Epoch [5/5], Batch [64], Loss: 2.0353\n",
            "Epoch [5/5], Batch [65], Loss: 1.9300\n",
            "Epoch [5/5], Batch [66], Loss: 2.0930\n",
            "Epoch [5/5], Batch [67], Loss: 1.9155\n",
            "Epoch [5/5], Batch [68], Loss: 1.9804\n",
            "Epoch [5/5], Batch [69], Loss: 2.3941\n",
            "Epoch [5/5], Batch [70], Loss: 2.0834\n",
            "Epoch [5/5], Batch [71], Loss: 2.1335\n",
            "Epoch [5/5], Batch [72], Loss: 1.9834\n",
            "Epoch [5/5], Batch [73], Loss: 1.9718\n",
            "Epoch [5/5], Batch [74], Loss: 2.2049\n",
            "Epoch [5/5], Batch [75], Loss: 2.0105\n",
            "Epoch [5/5], Batch [76], Loss: 2.2603\n",
            "Epoch [5/5], Batch [77], Loss: 1.9336\n",
            "Epoch [5/5], Batch [78], Loss: 1.8263\n",
            "Epoch [5/5], Batch [79], Loss: 1.9076\n",
            "Epoch [5/5], Batch [80], Loss: 2.1796\n",
            "Epoch [5/5], Batch [81], Loss: 2.0154\n",
            "Epoch [5/5], Batch [82], Loss: 2.0566\n",
            "Epoch [5/5], Batch [83], Loss: 2.3709\n",
            "Epoch [5/5], Batch [84], Loss: 1.8141\n",
            "Epoch [5/5], Batch [85], Loss: 2.2193\n",
            "Epoch [5/5], Batch [86], Loss: 1.8720\n",
            "Epoch [5/5], Batch [87], Loss: 1.9810\n",
            "Epoch [5/5], Batch [88], Loss: 2.0046\n",
            "Epoch [5/5], Batch [89], Loss: 1.8445\n",
            "Epoch [5/5], Batch [90], Loss: 2.2114\n",
            "Epoch [5/5], Batch [91], Loss: 2.0955\n",
            "Epoch [5/5], Batch [92], Loss: 1.8835\n",
            "Epoch [5/5], Batch [93], Loss: 2.0041\n",
            "Epoch [5/5], Batch [94], Loss: 1.9053\n",
            "Epoch [5/5], Batch [95], Loss: 1.9115\n",
            "Epoch [5/5], Batch [96], Loss: 1.9187\n",
            "Epoch [5/5], Batch [97], Loss: 1.8701\n",
            "Epoch [5/5], Batch [98], Loss: 1.7609\n",
            "Epoch [5/5], Batch [99], Loss: 1.8111\n",
            "Epoch [5/5], Batch [100], Loss: 2.1097\n",
            "Epoch [5/5] completed.\n",
            "Evaluating VAE performance after Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCD: 0.4433\n",
            "Training completed successfully!\n"
          ]
        }
      ]
    }
  ]
}